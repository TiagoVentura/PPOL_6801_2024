[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nWeek 01\n\n\nIntroduction, Overview of the course\n\n\nJanuary 17, 2024\n\n\n\n\nWeek 02\n\n\nFrom Text to Matrices: Representing Text as Data\n\n\nJanuary 24, 2024\n\n\n\n\nWeek 03\n\n\nText Similarity, Text re-use and Complexity\n\n\nJanuary 31, 2024\n\n\n\n\nWeek 04\n\n\nSupervised Learning I: Dictionary Methods and Out of Box Classifier Analysis\n\n\nFebruary 07, 2024\n\n\n\n\nWeek 05\n\n\nSupervised Learning II: Training your own classifiers\n\n\nFebruary 14, 2024\n\n\n\n\nWeek 06\n\n\nReplication Class I: Students’ Presentation\n\n\nFebruary 21, 2023\n\n\n\n\nWeek 07\n\n\nUnsupervised Learning: Topic Models\n\n\nFebruary 28, 2024\n\n\n\n\nWeek 08\n\n\nWord Embeddings: What are they and how to estimate?\n\n\nMarch 13, 2024\n\n\n\n\nWeek 09\n\n\nWord Embeddings: Social Science Applications\n\n\nMarch 20, 2024\n\n\n\n\nWeek 10\n\n\nUsing Text to Measure Ideology - Scaling\n\n\nMarch 27, 2024\n\n\n\n\nWeek 11\n\n\nReplication Class II\n\n\nApril 03, 2024\n\n\n\n\nWeek 12\n\n\nLarge Language Models: Theory and Fine-tuning a Transformers-based model (Invited Speaker Dr. Sebastian Vallejo)\n\n\nApril 10, 2024\n\n\n\n\nWeek 13\n\n\nLarge Language Models: Outsourcing Applications\n\n\nApril 17, 2023\n\n\n\n\nWeek 14\n\n\nPresentations of Final Projects\n\n\nApril 24, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "schedule.html#weekly-schedule",
    "href": "schedule.html#weekly-schedule",
    "title": "Schedule",
    "section": "",
    "text": "Week\n\n\nTopic\n\n\nDate\n\n\n\n\n\n\nWeek 01\n\n\nIntroduction, Overview of the course\n\n\nJanuary 17, 2024\n\n\n\n\nWeek 02\n\n\nFrom Text to Matrices: Representing Text as Data\n\n\nJanuary 24, 2024\n\n\n\n\nWeek 03\n\n\nText Similarity, Text re-use and Complexity\n\n\nJanuary 31, 2024\n\n\n\n\nWeek 04\n\n\nSupervised Learning I: Dictionary Methods and Out of Box Classifier Analysis\n\n\nFebruary 07, 2024\n\n\n\n\nWeek 05\n\n\nSupervised Learning II: Training your own classifiers\n\n\nFebruary 14, 2024\n\n\n\n\nWeek 06\n\n\nReplication Class I: Students’ Presentation\n\n\nFebruary 21, 2023\n\n\n\n\nWeek 07\n\n\nUnsupervised Learning: Topic Models\n\n\nFebruary 28, 2024\n\n\n\n\nWeek 08\n\n\nWord Embeddings: What are they and how to estimate?\n\n\nMarch 13, 2024\n\n\n\n\nWeek 09\n\n\nWord Embeddings: Social Science Applications\n\n\nMarch 20, 2024\n\n\n\n\nWeek 10\n\n\nUsing Text to Measure Ideology - Scaling\n\n\nMarch 27, 2024\n\n\n\n\nWeek 11\n\n\nReplication Class II\n\n\nApril 03, 2024\n\n\n\n\nWeek 12\n\n\nLarge Language Models: Theory and Fine-tuning a Transformers-based model (Invited Speaker Dr. Sebastian Vallejo)\n\n\nApril 10, 2024\n\n\n\n\nWeek 13\n\n\nLarge Language Models: Outsourcing Applications\n\n\nApril 17, 2023\n\n\n\n\nWeek 14\n\n\nPresentations of Final Projects\n\n\nApril 24, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "",
    "text": "In recent years, the surge in the availability of textual data, ranging from the digitalization of archival documents, political speeches, social media posts, and online news articles, has led to a growing demand for statistical analysis using large volumes of text data. In this course, we will teach students how to analyze and somewhat collect this data from a social science viewpoint. The focus is on understanding the real-world use of text as data rather than just the theory behind it. Students will learn how to acquire text, turn text into data, and analyze it to answer important policy-relevant questions. Each week, we’ll go over different methods, like building and using dictionaries, understanding sentiment in text, scaling texts on ideological and policy dimensions, and using machine learning to classify text. Lectures will include hands-on activities, letting students work directly with actual texts, and I strongly encourage students to bring their own data to class. The course aims to equip students with a variety of text analysis techniques that will be valuable for their future work as policy experts and computational social scientists.\nWhile the course covers an interdisciplinary topic, and many of the techniques we discuss have their origins in computer science or statistics, we will spend relatively little time on traditional Natural Language Processing techniques, such as machine translation, optical character recognition, and parts of speech tagging, etc. Although we will touch on Large Language Models (ChatGPT) at the end of the course, we will focus mostly on the practical use of these models through their APIs instead of building up and providing an in-depth understanding of their architecture.\nI assume students taking this class have taken, at minimum, an introductory class in statistics and have basic knowledge of probability, distributions, hypothesis testing, and linear models. The core language and software environment of this course is R. If you are not familiar with R, you will struggle with the assigned exercises. We will also provide some code in Python, but no prior knowledge here is assumed since this will be additional material."
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "",
    "text": "In recent years, the surge in the availability of textual data, ranging from the digitalization of archival documents, political speeches, social media posts, and online news articles, has led to a growing demand for statistical analysis using large volumes of text data. In this course, we will teach students how to analyze and somewhat collect this data from a social science viewpoint. The focus is on understanding the real-world use of text as data rather than just the theory behind it. Students will learn how to acquire text, turn text into data, and analyze it to answer important policy-relevant questions. Each week, we’ll go over different methods, like building and using dictionaries, understanding sentiment in text, scaling texts on ideological and policy dimensions, and using machine learning to classify text. Lectures will include hands-on activities, letting students work directly with actual texts, and I strongly encourage students to bring their own data to class. The course aims to equip students with a variety of text analysis techniques that will be valuable for their future work as policy experts and computational social scientists.\nWhile the course covers an interdisciplinary topic, and many of the techniques we discuss have their origins in computer science or statistics, we will spend relatively little time on traditional Natural Language Processing techniques, such as machine translation, optical character recognition, and parts of speech tagging, etc. Although we will touch on Large Language Models (ChatGPT) at the end of the course, we will focus mostly on the practical use of these models through their APIs instead of building up and providing an in-depth understanding of their architecture.\nI assume students taking this class have taken, at minimum, an introductory class in statistics and have basic knowledge of probability, distributions, hypothesis testing, and linear models. The core language and software environment of this course is R. If you are not familiar with R, you will struggle with the assigned exercises. We will also provide some code in Python, but no prior knowledge here is assumed since this will be additional material."
  },
  {
    "objectID": "index.html#class-website",
    "href": "index.html#class-website",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "Class Website",
    "text": "Class Website\nhttps://tiagoventura.github.io/PPOL_6801_2024/"
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "Instructor",
    "text": "Instructor\nProfessor Tiago Ventura\n\nPronouns: He/Him\nEmail: tv186@georgetown.edu\nOffice hours: Every Tuesday, 4pm - 6pm\nLocation: Old north, 312\n\n\n\n\n\n\n\nWhen should I go to your office hours?\n\n\n\n\n\n\nYou are all welcome to the office hours. You can come to the office hours to:\n\ndrink some coffee;\ntalk about soccer;\nAsk what I am doing research at;\nAsk any question about our class.\n\nAll are valid options! And no need to schedule time with me!"
  },
  {
    "objectID": "index.html#course-infra-structure",
    "href": "index.html#course-infra-structure",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "Course Infra-structure",
    "text": "Course Infra-structure\nClass Website: This class website will be used throughout the course and should be checked on a regular basis for lecture materials and required readings.\nClass Slack Channel: The class also has a dedicated slack channel. The channel serves as an open forum to discuss, collaborate, pose problems/questions, and offer solutions. Students are encouraged to pose any questions they have there as this will provide the professor the means of answering the question so that all can see the response. If you’re unfamiliar with, please consult the following start-up tutorial https://get.slack.help/hc/en-us/articles/218080037-Getting-started-for-new-members. Please follow the invite link to be added to the Slack channel.\nCanvas: A Canvas site http://canvas.georgetown.edu will be used throughout the course and should be checked on a regular basis for announcements. Materials will be posted here, and not on canvas, or distributed in class or by e-mail. Support for Canvas is available at (202) 687-4949"
  },
  {
    "objectID": "weeks/week-01.html",
    "href": "weeks/week-01.html",
    "title": "Week 01",
    "section": "",
    "text": "Topics\n\nReview of syllabus\nClass organization\nGetting to know you\nIntroduction to computational text analysis.\n\n\n\nReadings\nRequired Readings\n\nGrimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. Text as data: A new framework for machine learning and the social sciences. Princeton University Press, 2022 - Chapter 2.\n\nOr one of the three below:\n\nPolitical Science Perspective: Wilkerson, J. and Casas, A. (2017). Large-Scale Computerized Text Analysis in Political Science: Opportunities and Challenges. Annual Review of Political Science, 20, 529:544.\nEconomics Perspective: Gentzkow, Matthew, Bryan Kelly, and Matt Taddy. “Text as data.” Journal of Economic Literature 57, no. 3 (2019): 535-574.\nSociology Perspective: https://www.sciencedirect.com/science/article/pii/S0049089X22000904\n\nCoding Materials\n\nNone\n\n\n\nSlides\n\nWeek 1 - Introduction"
  },
  {
    "objectID": "weeks/week-02.html",
    "href": "weeks/week-02.html",
    "title": "Week 02",
    "section": "",
    "text": "Topics\n\nHow to represent text as data?\nWhat is a Bag of Words?\nWhat are tokens?\nWhy should we care about tokens?\n\n\n\nReadings\nRequired Readings\n\nGrimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. Text as data: A new framework for machine learning and the social sciences. Princeton University Press, 2022 - Chapters 3-5\nApplied Papers:\nDenny, M. J., & Spirling, A. (2018). Text preprocessing for unsupervised learning: why it matters, when it misleads, and what to do about it. Political Analysis, 26(2): 168-189.\nBan, Pamela, Alexander Fouirnaies, Andrew B. Hall, and James M. Snyder. “How newspapers reveal political power.” Political Science Research and Methods 7, no. 4 (2019): 661-678.\nMichel, J.B., et al. 2011. “Quantitative Analysis of Culture Using Millions of Digitized Books.” Science 331 (6014): 176–82. https://doi.org/10.1126/science.1199644\n\nCoding Materials\n\n Week 2 - Text Data Processing, \n\n\n\nSlides\n\nWeek 2 - From Text to Matrices: Representing Text as Data"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Topics\n\n\nReadings\nRequired Readings\n\nWu, Patrick Y., Joshua A. Tucker, Jonathan Nagler, and Solomon Messing. “Large language models can be used to estimate the ideologies of politicians in a zero-shot learning setting.” arXiv preprint arXiv:2303.12057 (2023).\n\n- [Rathje, Steve, Dan-Mircea Mirea, Ilia Sucholutsky, Raja Marjieh, Claire Robertson, and Jay J. Van Bavel. GPT is an effective tool for multilingual psychological text analysis. (2023)](https://osf.io/preprints/psyarxiv/sekf5).\n\n- [Davidson, Thomas: Start Generating: Harnessing Generative Artificial Intelligence for Sociological Research, PrePrint](https://osf.io/preprints/socarxiv/u9nft)\n\n- [Bisbee, James, Joshua Clinton, Cassy Dorff, Brenton Kenkel, and Jennifer Larson. 2023. “Synthetic Replacements for Human Survey Data? the Perils of Large Language Models.” SocArXiv. May 4.](https://osf.io/preprints/socarxiv/5ecfa) \nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-04.html",
    "href": "weeks/week-04.html",
    "title": "Week 04",
    "section": "",
    "text": "Topics\n\nWhat are dictionaries?\nWhy/when are they useful?\nWhat are their limitations?\nCan we use models trained by others and for other purposes in our classification tasks?\n\n\n\nReadings\nRequired Readings\n\n[GMB] - Chapters 15-16\nApplied Papers:\n\nLori Young and Stuart Soroka 2012 “Affective News: The Automated Coding of Sentiment in Political Texts.” Political Communication, 29:2, 205-231.\nRathje, Steve, Jay J. Van Bavel, and Sander Van Der Linden. “Out-group animosity drives engagement on social media.” Proceedings of the National Academy of Sciences 118, no. 26 (2021): e2024292118.\nVentura, Tiago, Kevin Munger, Katherine McCabe, and Keng-Chi Chang. “Connective effervescence and streaming chat during political debates.” Journal of Quantitative Description: Digital Media 1 (2021).\n\n\nCoding Materials\n\nTBD\n\n\n\nProblem set 1\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-08.html",
    "href": "weeks/week-08.html",
    "title": "Week 08",
    "section": "",
    "text": "Topics\n\nWhat are word-embeddings?\nWhen and how can we use them?\nWhat? Topic models again?\nIs this still a bag of words?\n\n\n\nReadings\nRequired Readings\n\n[GMB] - Chapter 8.\n[SLP] Chapter 6, “Vector Semantics and Embeddings.”\nMeyer, David. How Exactly Does Word2Vec Work?\nSpirling and Rodriguez, Word embedding: What works, what doesn’t, and how to tell the difference for applied research.\n\nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-09.html",
    "href": "weeks/week-09.html",
    "title": "Week 09",
    "section": "",
    "text": "Topics\n\nApplications of Word Embeddings to social science problems\n\n\n\nReadings\nRequired Readings\n-  Rodman, E., 2020. A Timely Intervention: Tracking the Changing Meanings of Political Concepts with Word Vectors. Political Analysis, 28(1), pp.87-111.\n\n- Gennaro, Gloria, and Elliott Ash. \"Emotion and reason in political language.\" The Economic Journal 132, no. 643 (2022): 1037-1059.\n\n- Rheault, Ludovic, and Christopher Cochrane. \"Word embeddings for the analysis of ideological placement in parliamentary corpora.\" Political Analysis 28, no. 1 (2020): 112-133.\n\n- Austin C. Kozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings.” American Sociological Review 84, no. 5: 905–49. https://doi.org/10.1177/0003122419877135.\n\n- Garg, Nikhil, Londa Schiebinger, Dan Jurafsky and James Zou. 2018. “Word embeddings quantify 100 years of gender and ethnic stereotypes.” Proceedings of the National Academy of Sciences 115(16):E3635–E3644.\nCoding Materials\n\nTBD\n\n\n\nProblem Set 3\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Topics\n\nWhat are scaling models and what can they tell us?\nCan we represent politicians/users ideology using text?\n\n\n\nReadings\nRequired Readings\n\nLaver, Michael, Kenneth Benoit, and John Garry. 2003. “Extracting Policy Positions from Political Texts Using Words as Data”. American Political Science Review. 97, 2, 311-331\nSlapin, Jonathan and Sven-Oliver Prokschk. 2008. “A Scaling Model for Estimating Time-Series Party Positions from Texts.” American Journal of Political Science. 52, 3 705-722\n\n- Rheault, Ludovic, and Christopher Cochrane. \"Word embeddings for the analysis of ideological placement in parliamentary corpora.\" Political Analysis 28, no. 1 (2020): 112-133.\n\n- Aruguete, Natalia, Ernesto Calvo, and Tiago Ventura. \"News by popular demand: Ideological congruence, issue salience, and media reputation in news sharing.\" The International Journal of Press/Politics 28, no. 3 (2023): 558-579.\n\n- Izumi, Mauricio Y., and Danilo B. Medeiros. \"Government and opposition in legislative speechmaking: using text-as-data to estimate Brazilian political parties’ policy positions.\" Latin American Politics and Society 63, no. 1 (2021): 145-164.\nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-05.html",
    "href": "weeks/week-05.html",
    "title": "Week 05",
    "section": "",
    "text": "Topics\nWe will study the framework to train our own supervised models, and when to use them.\n\n\nReadings\nRequired Readings\n\n[GMB] - Chapters 17, 18, 19, and 20.\nApplied Papers:\n\nBarberá, Pablo, Amber E. Boydstun, Suzanna Linn, Ryan McMahon, and Jonathan Nagler. “Automated text classification of news articles: A practical guide.” Political Analysis 29, no. 1 (2021): 19-42.\nSiegel, Alexandra, et al. “Trumping Hate on Twitter? Online Hate Speech in the 2016 US Election Campaign and its Aftermath.”\nTheocharis, Y., Barberá, P., Fazekas, Z., & Popa, S. A. (2020). The dynamics of political incivility on Twitter. Sage Open, 10(2), 2158244020919447.\nMitts, T., Phillips, G., & Walter, B. (2021). Studying the Impact of ISIS Propaganda Campaigns. Journal of Politics\n\n\nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-07.html",
    "href": "weeks/week-07.html",
    "title": "Week 07",
    "section": "",
    "text": "Topics\n-what if we do not have an outcome to predict? - can we cluster the text in groups? - what are topics? - how to decide between different topics?\n\n\nReadings\nRequired Readings\n\n[GMB] - Chapters 12-14.\nDavid M. Blei . 2012. “Probabilistic Topic Models.” http://www.cs.columbia.edu/~blei/papers/ Blei2012.pdf\nApplied Papers:\n\nMotolinia, Lucia. Electoral accountability and particularistic legislation: evidence from an electoral reform in Mexico. American Political Science Review 115, no. 1 (2021): 97-113.\nBarberá, P., Casas, A., Nagler, J., Egan, P. J., Bonneau, R., Jost, J. T., & Tucker, J. A. (2019). Who leads? Who follows? Measuring issue attention and agenda setting by legislators and the mass public using social media data. American Political Science Review, 113(4), 883-901.\nEshima, Shusei, Kosuke Imai, and Tomoya Sasaki. “Keyword‐Assisted Topic Models.” American Journal of Political Science (2020).\n\n\nCoding Materials\n\nTBD\n\n\n\nProblem Set 2\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Topics\n\nWe will learn about the Transformers architecture, attention, and the encoder-coder infrastructure.\n\n\n\nReadings\nRequired Readings\n\n[SLP] - Chapter 10.\nJay Alammar. 2018. “The Illustrated Transformer.” https://jalammar.github.io/illustratedtransformer/\nVaswani, A., et al. (2017). Attention is all you need. Advances in neural information processing systems, 30;\nTimoneda and Vera, BERT, RoBERTa or DeBERTa? Comparing Performance Across Transformer Models in Political Science Text, Forthcoming Journal of Politics.\n\nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "weeks/week-03.html",
    "href": "weeks/week-03.html",
    "title": "Week 03",
    "section": "",
    "text": "Topics\n\nHow do we evaluate complexity in text?\nWhy should we care about complexity in text?\nHow do we evaluate similarity in text?\nWhy is this useful?\n\n\n\nReadings\nRequired Readings\n\n[GMB] - Chapter 7\nApplied Papers:\n\nSpirling, Arthur. 2016. “Democratization and Linguistic Complexity”, Journal of Politics.\nBenoit, K., Munger, K. and Spirling, A. 2017. Measuring and Explaining Political Sophistication Through Textual Complexity\nLinder, Fridolin, Bruce Desmarais, Matthew Burgess, and Eugenia Giraudy. “Text as policy: Measuring policy similarity through bill text reuse.” Policy Studies Journal 48, no. 2 (2020): 546-574.\n\n\nCoding Materials\n\nTBD\n\n\n\nSlides\n\nTBD"
  },
  {
    "objectID": "slides/week_01_intro.html#outline",
    "href": "slides/week_01_intro.html#outline",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Outline",
    "text": "Outline\n\n\nIntroduction (me)\nMotivation for Computational Linguistics\n\nDigital information age\nPrinciples of Computational Linguistics.\nWhat this course is not.\nExamples of models and applications for this course\n\nIntroductions (you)\nClass Logistics ( + 10 min for you to read through the syllabus)\nQ&A\nAcquiring text in the web (Jupyter notebooks for scrapping)"
  },
  {
    "objectID": "slides/week_01_intro.html#introduction",
    "href": "slides/week_01_intro.html#introduction",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Introduction",
    "text": "Introduction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessor Tiago Ventura (he/him)\n\nAssistant Professor at McCourt School.\nPolitical Science Ph.D.\nPostdoc at Center for Social Media and Politics - NYU.\nResearcher at Twitter.\n\nSome Projects I am involved\n\nGlobal Social Media Deactivation.\nEffects of WhatsApp on Elections in the Global South.\nAI and Misinformation in 2024 elections.\nPanels of voter files and twitter users.\n\nOutside of work, I enjoy watching soccer, reading sci-fi and running"
  },
  {
    "objectID": "slides/week_01_intro.html#rise-of-the-digital-information-age",
    "href": "slides/week_01_intro.html#rise-of-the-digital-information-age",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Rise of the digital information age",
    "text": "Rise of the digital information age"
  },
  {
    "objectID": "slides/week_01_intro.html#official-documents-congressional-speeches-bills-press-releases-transcripts-from-all-over-the-world",
    "href": "slides/week_01_intro.html#official-documents-congressional-speeches-bills-press-releases-transcripts-from-all-over-the-world",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Official Documents: Congressional Speeches, Bills, Press Releases, Transcripts, from all over the world!!",
    "text": "Official Documents: Congressional Speeches, Bills, Press Releases, Transcripts, from all over the world!!"
  },
  {
    "objectID": "slides/week_01_intro.html#social-media",
    "href": "slides/week_01_intro.html#social-media",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Social Media",
    "text": "Social Media"
  },
  {
    "objectID": "slides/week_01_intro.html#the-internet-news-comments-blogs-etc",
    "href": "slides/week_01_intro.html#the-internet-news-comments-blogs-etc",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "The internet: News, Comments, Blogs, etc…",
    "text": "The internet: News, Comments, Blogs, etc…"
  },
  {
    "objectID": "slides/week_01_intro.html#what-is-this-class-about",
    "href": "slides/week_01_intro.html#what-is-this-class-about",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "What is this class about?",
    "text": "What is this class about?\n\nFor many years, social scientists use text in their analysis\nMostly through in-depth reading of documents.\nClose Reading. Humans are great at this!\nDigital Revolution:\n\nProduction of text increased\nThe capacity to analyze them at scale as well.\n\nThis class covers methods (and many applications) of using text as data to answer social science problems and test social science theories\nComputational Linguistics ~ Distant Reading. Computers are better at understanding patterns, classify and describe content across millions of documents."
  },
  {
    "objectID": "slides/week_01_intro.html#principles-of-text-analysis-gmb-textbook",
    "href": "slides/week_01_intro.html#principles-of-text-analysis-gmb-textbook",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Principles of Text Analysis (GMB Textbook)",
    "text": "Principles of Text Analysis (GMB Textbook)\n\nPrinciple 1: Social science theories and substantive knowledge are essential for research design\nPrinciple 2: Text analysis does not replace humans—it augments them.\nPrinciple 3: Building, refining, and testing social science theories requires iteration and cumulation.\nPrinciple 4: Text analysis methods distill generalizations from language. (all models are wrong!)\nPrinciple 5: The best method depends on the task. (Qualitative knowledge)\nPrinciple 6: Validations are essential and depend on the theory and the task"
  },
  {
    "objectID": "slides/week_01_intro.html#challenges-i-text-is-an-unstructure-data-source",
    "href": "slides/week_01_intro.html#challenges-i-text-is-an-unstructure-data-source",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenges I: Text is an unstructure data source",
    "text": "Challenges I: Text is an unstructure data source"
  },
  {
    "objectID": "slides/week_01_intro.html#challenge-ii-text-is-high-dimensionality",
    "href": "slides/week_01_intro.html#challenge-ii-text-is-high-dimensionality",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenge II: Text is High dimensionality",
    "text": "Challenge II: Text is High dimensionality\nFrom Gentzkow et al 2017:\n\nsample of documents, each \\(n_L\\) words long, drawn from vocabulary of \\(n_V\\) words.\nThe unique representation of each document has dimension \\(n_{V}^{n_L}\\) .\n\ne.g., a sample of 30-word (\\(n_L\\)) Twitter messages using only the one thousand most common words in the English language\nDimensionality = \\(1000^{30}\\)\nAs a matrix: \\(M^{1000}_{n_tweets}\\)\n\nMost of what you learned in statistics so far does not equip you to deal with this curse of dimensionality."
  },
  {
    "objectID": "slides/week_01_intro.html#text-as-data-workflow",
    "href": "slides/week_01_intro.html#text-as-data-workflow",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Text-as-Data Workflow",
    "text": "Text-as-Data Workflow\n\nAcquire textual data:\n\nExisting corpora; scraped data; digitized text"
  },
  {
    "objectID": "slides/week_01_intro.html#text-as-data-workflow-1",
    "href": "slides/week_01_intro.html#text-as-data-workflow-1",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Text-as-Data Workflow",
    "text": "Text-as-Data Workflow\n\nMap Documents to a numerical representation M\n\nBag-of-words (sparse vectors)\nEmbeddings (dense vectors)\nReduce noise, capture signal"
  },
  {
    "objectID": "slides/week_01_intro.html#text-as-data-workflow-2",
    "href": "slides/week_01_intro.html#text-as-data-workflow-2",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Text-as-Data Workflow",
    "text": "Text-as-Data Workflow\n\nMap M to predicted values \\(V^{*}\\) of unknown outcomes V\n\nDescriptive Analysis\nClassify documents into unknown categories\n\nTopic models\n\nClassify documents into known categories\n\nDictionary methods\nSupervised machine learning\nTransfer-Learning - use models trained in text for other purposes\n\nScale documents on latent dimension:"
  },
  {
    "objectID": "slides/week_01_intro.html#text-as-data-workflow-3",
    "href": "slides/week_01_intro.html#text-as-data-workflow-3",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Text-as-Data Workflow",
    "text": "Text-as-Data Workflow\n\nUse \\(V^{*}\\) in subsequent analysis with other data sources\n\nThis is where social science happens!"
  },
  {
    "objectID": "slides/week_01_intro.html#assume-you-already-did-it",
    "href": "slides/week_01_intro.html#assume-you-already-did-it",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Assume you already did it!",
    "text": "Assume you already did it!\n\nAcquire textual data: Existing corpora; scraped data; digitized text"
  },
  {
    "objectID": "slides/week_01_intro.html#some-cool-applications",
    "href": "slides/week_01_intro.html#some-cool-applications",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Some cool applications",
    "text": "Some cool applications\n\nMeasure text-reuse across thousands of bills from U.S. state legislatures\nEstimate levels of toxicity of comments from stremming chats platforms during political debates\nMeasure how out-group negative makes things go viral on social media\nMeasure the policy target of bills proposals in Mexico\nEstimate ideological positions using who a user follows on Twitter, what a user share on social media, political manifestos, or just asking ChatGPT to pair-wise compare politicians"
  },
  {
    "objectID": "slides/week_01_intro.html#what-this-class-in-not-about-it",
    "href": "slides/week_01_intro.html#what-this-class-in-not-about-it",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "What this class in not about it…",
    "text": "What this class in not about it…\n\nData acquisition: no scrapping in class. Assume you have learned already.\nRegular expressions and basic text manipulation.\nCS Stuff: machine translation, OCR, POS, entity recognition.\n\nMost NLP/CS will focus on developing new algorithms, information retrievel and purely better measurements.\nin a productive dialogue with NLP, we will focus on using text for social science research\n\ntheoretically driven discovery and measurement\nintegration with social science problems + tabular data."
  },
  {
    "objectID": "slides/week_01_intro.html#your-turn",
    "href": "slides/week_01_intro.html#your-turn",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Your turn!",
    "text": "Your turn!\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n\nName & pronouns\nWhy are you taking this course?\nYour experience (if any) working with text\nThe most interesting thing you learned in the DSPP so far"
  },
  {
    "objectID": "slides/week_01_intro.html#read-the-syllabus",
    "href": "slides/week_01_intro.html#read-the-syllabus",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Read the syllabus!",
    "text": "Read the syllabus!\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/week_01_intro.html#class-requirements",
    "href": "slides/week_01_intro.html#class-requirements",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Class Requirements",
    "text": "Class Requirements\n\nAssume you all have a intro course in statistics and probability (which I know you do)\nMath: Basic knowledge of calculus, probability, densities, distributions, statistical tests, hypothesis testing, the linear model, maximum likelihood and generalized linear models is assumed.\nProgramming: Functional knowledge of R - main programming language of the course. Some Python at the end.\n\nR is excellent for text analysis, and for some social science applications, better than Python\nFree, and massive online community writing packages and extending modeling capabilities.\nWe will divide our learning between using tidytext and quanteda for text analysis.\nDownload RStudio IDE!"
  },
  {
    "objectID": "slides/week_01_intro.html#how-to-do-well-in-the-class",
    "href": "slides/week_01_intro.html#how-to-do-well-in-the-class",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "How to do well in the class?",
    "text": "How to do well in the class?\nI designed this course as PhD style seminar:\n\nSo far, you learned a lot of DS techniques (DS I, DS II, DS III)\nYou haven’t dig deep enough in a particular field. That’s what electives are for!\nHeavy on readings - Lot’s of applied and technical readings.\nDo the readings before class\nSubstantive readings are especially important, because they’ll help you understand what an interesting question looks like – in social science/public policy.\nPlan ahead – particularly for the replication exercise\nIf you have a corpus you want work with, please bring it to class!"
  },
  {
    "objectID": "slides/week_01_intro.html#what-our-classes-will-look-like.",
    "href": "slides/week_01_intro.html#what-our-classes-will-look-like.",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "What our classes will look like.",
    "text": "What our classes will look like.\nThis is a one meeting per week class. You should expect:\n\nBetween 1h-1.5h of lecture based on this week topics + readings\nYour participation in the lecture is expected I will ask your insights about the readings.\nBreak (10min)\nCoding.\n\nMix of you working through some code I prepared.\nAnd I live-coding for you."
  },
  {
    "objectID": "slides/week_01_intro.html#textbook",
    "href": "slides/week_01_intro.html#textbook",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Textbook",
    "text": "Textbook"
  },
  {
    "objectID": "slides/week_01_intro.html#logistics",
    "href": "slides/week_01_intro.html#logistics",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Logistics",
    "text": "Logistics\n\nCommunication: via slack. Join the channel!\nAll materials: hosted on the class website: https://tiagoventura.github.io/PPOL_6801_2024//\nSyllabus: also on the website.\nMy Office Hours: Every Tuesday from 4 to 6pm. Just stop by!\nCanvas: Only for communication! Materials will be hosted in the website!"
  },
  {
    "objectID": "slides/week_01_intro.html#evalutation",
    "href": "slides/week_01_intro.html#evalutation",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Evalutation",
    "text": "Evalutation\n\n\n\nAssignment\nPercentage of Grade\n\n\n\n\nParticipation/Attendance\n10%\n\n\nProblem Sets\n20%\n\n\nReplication Exercises\n30%\n\n\nFinal Project\n40%"
  },
  {
    "objectID": "slides/week_01_intro.html#participation",
    "href": "slides/week_01_intro.html#participation",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Participation",
    "text": "Participation\n\nActive involvement during class sessions, fostering a dynamic learning environment.\nContributions made to your group’s ultimate project.\nAssisting classmates with slack questions, sharing interesting materials on slack, asking question, and anything that provides healthy contributions to the course."
  },
  {
    "objectID": "slides/week_01_intro.html#problem-sets",
    "href": "slides/week_01_intro.html#problem-sets",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Problem Sets",
    "text": "Problem Sets\n\n\n\nAssignment\nDate Assigned\nDate Due\n\n\n\n\nNo. 1\nWeek 4\nBefore EOD of Week 5’s class\n\n\nNo. 2\nWeek 7\nBefore EOD of Week 8’s class\n\n\nNo. 3\nWeek 9\nBefore EOD of Week 10’s class\n\n\n\n\nYou will have a week to complete your assignments\nindividual assignment\ndistributed through github"
  },
  {
    "objectID": "slides/week_01_intro.html#replication-exercises",
    "href": "slides/week_01_intro.html#replication-exercises",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Replication Exercises",
    "text": "Replication Exercises\nOpportunity to learn how science is made!\nWork in randomly assigned pairs I will post on Slack.\n\nStep 1: finding a paper to replicate (from the syllabus)\n\nBy the end of the week 2 and week 7, you should select an article from the syllabus to be replicated by your team.\nInform the class on slack\n“first come, first served”\n\nStep 2: Acquiring the Data\n\nif you fail to get the data, pick another article.\n\nStep 3: Presentation (weeks 6 and 11)\nStep 4: Replication Repository on Github"
  },
  {
    "objectID": "slides/week_01_intro.html#final-project",
    "href": "slides/week_01_intro.html#final-project",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Final Project",
    "text": "Final Project\nThe project is composed of three parts:\n\na 2 page project proposal: (which should be discussed and approved by me)\nan in-class presentation,\nA 10-page project report.\n\n\n\n\n\n\n\n\n\n\nRequirement\nDue\nLength\nPercentage\n\n\n\n\nProject Proposal\nEOD Friday Week 9\n2 pages\n5%\n\n\nPresentation\nWeek 14\n10-15 minutes\n10%\n\n\nProject Report\nWednesday Week 15\n10 pages\n25%"
  },
  {
    "objectID": "slides/week_01_intro.html#chatgpt",
    "href": "slides/week_01_intro.html#chatgpt",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "ChatGPT",
    "text": "ChatGPT\n\nYou are allowed to use ChatGPT as you would use google in this class. This means:\n\nDo not copy the responses from chatgpt – a lot of them are wrong or will just not run on your computer\nUse chatgpt as a auxiliary source.\nIf your entire homework comes straight from chatgpt, I will consider it plagiarism.\nIf you use chatgpt, I ask you to mention on your code how chatgpt worked for you."
  },
  {
    "objectID": "slides/week_01_intro.html#acquiring-text",
    "href": "slides/week_01_intro.html#acquiring-text",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Acquiring text:",
    "text": "Acquiring text:\n\nAs a review, here are some notebooks I developed for Data Science I introducing a full toolkit for acquiring data in the web:\n\nStatic Websites\nAPIs\nSelenium for Dynamics Websites\n\n\n\n\nText-as-Data"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "",
    "text": "Download a PDF Version here"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Course Description",
    "text": "Course Description\nIn recent years, the surge in the availability of textual data, ranging from the digitalization of archival documents, political speeches, social media posts, and online news articles, has led to a growing demand for statistical analysis using large volumes of text data. In this course, we will teach students how to analyze and somewhat collect this data from a social science viewpoint. The focus is on understanding the real-world use of text as data rather than just the theory behind it. Students will learn how to acquire text, turn text into data, and analyze it to answer important policy-relevant questions. Each week, we’ll go over different methods, like building and using dictionaries, understanding sentiment in text, scaling texts on ideological and policy dimensions, and using machine learning to classify text. Lectures will include hands-on activities, letting students work directly with actual texts, and I strongly encourage students to bring their own data to class. The course aims to equip students with a variety of text analysis techniques that will be valuable for their future work as policy experts and computational social scientists.\nWhile the course covers an interdisciplinary topic, and many of the techniques we discuss have their origins in computer science or statistics, we will spend relatively little time on traditional Natural Language Processing techniques, such as machine translation, optical character recognition, and parts of speech tagging, etc. Although we will touch on Large Language Models (ChatGPT) at the end of the course, we will focus mostly on the practical use of these models through their APIs instead of building up and providing an in-depth understanding of their architecture.\nI assume students taking this class have taken, at minimum, an introductory class in statistics and have basic knowledge of probability, distributions, hypothesis testing, and linear models. The core language and software environment of this course is R. If you are not familiar with R, you will struggle with the assigned exercises. We will also provide some code in Python, but no prior knowledge here is assumed since this will be additional material."
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Instructor",
    "text": "Instructor\nProfessor Tiago Ventura\n\nPronouns: He/Him\nEmail: tv186@georgetown.edu\nOffice hours: Every Tuesday, 4pm - 6pm\nLocation: Old north, 312"
  },
  {
    "objectID": "syllabus.html#our-classes",
    "href": "syllabus.html#our-classes",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Our classes",
    "text": "Our classes\nClasses will take place at the scheduled class time/place and will involve a combination of lectures, coding walkthrough, breakout group sessions, and questions. We will start our classes with a lecture highlighting what I consider to be the broader substantive and programming concepts covered in the class. From that, we will switch to a mix of coding walk through and breakout group sessions.\nThis class follows a more classic PhD style seminar. This means that the class is heavy on the readings, and I expect you to do the readings before class. For most classes, you will read one or more chapters of the text book and between two or three applied articles. Most of the lectures will cover topics discussed on the readings.\nNote that this class is scheduled to meet weekly for 2.5 hours. I will do my best to make our meetings dynamic and enjoyable for all parts involved. We will take one or two breaks in each of our lecture."
  },
  {
    "objectID": "syllabus.html#required-materials",
    "href": "syllabus.html#required-materials",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Required Materials",
    "text": "Required Materials\nReadings: We will rely primarily on the following textbooks for this course. While this textbook is not freely available online, all the other materials of the course will be or should be accessible through Georgetown library.\n\nGrimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. Text as data: A new framework for machine learning and the social sciences. Princeton University Press, 2022 - [GMB]\nDaniel Jurafsky and James H. Martin. Speech and Language Processing, 3nd Edition. - [SLP]\n\nThe weekly articles are listed in the syllabus"
  },
  {
    "objectID": "syllabus.html#course-infrastructure",
    "href": "syllabus.html#course-infrastructure",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Course Infrastructure",
    "text": "Course Infrastructure\nClass Website: A class website will be used throughout the course and should be checked on a regular basis for lecture materials and required readings.\nClass Slack Channel: The class also has a dedicated slack channel. The channel serves as an open forum to discuss, collaborate, pose problems/questions, and offer solutions. Students are encouraged to pose any questions they have there as this will provide the professor and TA the means of answering the question so that all can see the response. If you’re unfamiliar with, please consult the following start-up tutorial (https://get.slack.help/hc/en-us/articles/218080037-Getting-started-for-new-members).\nCanvas: A Canvas site (http://canvas.georgetown.edu) will be used throughout the course and should be checked on a regular basis for announcements and assignments. All announcements for the assignments and classes will be posted on Canvas; they will not be distributed in class or by e-mail. Support for Canvas is available at (202) 687-4949"
  },
  {
    "objectID": "syllabus.html#weekly-schedule-readings",
    "href": "syllabus.html#weekly-schedule-readings",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Weekly Schedule & Readings",
    "text": "Weekly Schedule & Readings\n\nWeek 1: Introduction - Overview of the course\nTopics: Review of syllabus and class organization. Introduction to computational text analysis.\n\n[GMB] - Chapter 2.\n\nOr one of the three below:\n\nPolitical Science Perspective: Wilkerson, J. and Casas, A. (2017). Large-Scale Computerized Text Analysis in Political Science: Opportunities and Challenges. Annual Review of Political Science, 20, 529:544.\nEconomics Perspective: Gentzkow, Matthew, Bryan Kelly, and Matt Taddy. “Text as data.” Journal of Economic Literature 57, no. 3 (2019): 535-574.\nSociology Perspective: https://www.sciencedirect.com/science/article/pii/S0049089X22000904\n\n\n\nWeek 2: From Text to Matrices: Representing Text as Data\nTopics: How to represent text as data? What is a Bag of Words? What are tokens? Why should we care about tokens?\n-[GMB] - Chapters 3-5\n\nApplied Papers:\n\nDenny, M. J., & Spirling, A. (2018). Text preprocessing for unsupervised learning: why it matters, when it misleads, and what to do about it. Political Analysis, 26(2): 168-189.\nBan, Pamela, Alexander Fouirnaies, Andrew B. Hall, and James M. Snyder. “How newspapers reveal political power.” Political Science Research and Methods 7, no. 4 (2019): 661-678.\nMichel, J.B., et al. 2011. “Quantitative Analysis of Culture Using Millions of Digitized Books.” Science 331 (6014): 176–82. https://doi.org/10.1126/science.1199644;\n\n\n\n\nWeek 3: Text Similarity, Text re-use and Complexity\nTopics: How do we evaluate complexity in text? Why should we care about complexity in text? How do we evaluate similarity in text? Why is this useful?\n\n[GMB] - Chapter 7\nApplied Papers:\n\nSpirling, Arthur. 2016. “Democratization and Linguistic Complexity”, Journal of Politics.\nBenoit, K., Munger, K. and Spirling, A. 2017. Measuring and Explaining Political Sophistication Through Textual Complexity\nLinder, Fridolin, Bruce Desmarais, Matthew Burgess, and Eugenia Giraudy. “Text as policy: Measuring policy similarity through bill text reuse.” Policy Studies Journal 48, no. 2 (2020): 546-574.\n\n\n\n\nWeek 4: Supervised Learning I: Dictionary Methods and Out of Box Classifier Analysis\nTopics: What are dictionaries? Why/when are they useful? What are their limitations? Can we use models trained by others?\n\n[GMB] - Chapters 15-16\nApplied Papers:\n\nLori Young and Stuart Soroka 2012 “Affective News: The Automated Coding of Sentiment in Political Texts.” Political Communication, 29:2, 205-231.\nRathje, Steve, Jay J. Van Bavel, and Sander Van Der Linden. “Out-group animosity drives engagement on social media.” Proceedings of the National Academy of Sciences 118, no. 26 (2021): e2024292118.\nVentura, Tiago, Kevin Munger, Katherine McCabe, and Keng-Chi Chang. “Connective effervescence and streaming chat during political debates.” Journal of Quantitative Description: Digital Media 1 (2021).\n\nProblem set 1 Assigned\n\n\n\nWeek 5: Supervised Learning II: Training your own classifiers\nTopics: We will study the framework to train our own supervised models, and when to use them.\n\n[GMB] - Chapters 17, 18, 19, and 20.\nApplied Papers:\n\nBarberá, Pablo, Amber E. Boydstun, Suzanna Linn, Ryan McMahon, and Jonathan Nagler. “Automated text classification of news articles: A practical guide.” Political Analysis 29, no. 1 (2021): 19-42.\nSiegel, Alexandra, et al. “Trumping Hate on Twitter? Online Hate Speech in the 2016 US Election Campaign and its Aftermath.”\nTheocharis, Y., Barberá, P., Fazekas, Z., & Popa, S. A. (2020). The dynamics of political incivility on Twitter. Sage Open, 10(2), 2158244020919447.\nMitts, T., Phillips, G., & Walter, B. (2021). Studying the Impact of ISIS Propaganda Campaigns. Journal of Politics\n\n\n\n\nWeek 6: Replication Class I: Students’ Presentation\n\n\nWeek 7: Unsupervised Learning: Topic Models\nTopics: what if we do not have an outcome to predict? can we cluster the text in groups? what are topics?\n\n[GMB] - Chapters 12-14.\nDavid M. Blei . 2012. “Probabilistic Topic Models.” http://www.cs.columbia.edu/~blei/papers/ Blei2012.pdf\nApplied Papers:\n\nMotolinia, Lucia. Electoral accountability and particularistic legislation: evidence from an electoral reform in Mexico. American Political Science Review 115, no. 1 (2021): 97-113.\nBarberá, P., Casas, A., Nagler, J., Egan, P. J., Bonneau, R., Jost, J. T., & Tucker, J. A. (2019). Who leads? Who follows? Measuring issue attention and agenda setting by legislators and the mass public using social media data. American Political Science Review, 113(4), 883-901.\nEshima, Shusei, Kosuke Imai, and Tomoya Sasaki. “Keyword‐Assisted Topic Models.” American Journal of Political Science (2020).\n\nProblem set 2 Assigned\n\n\n\nWeek 8: Word Embeddings: What they are and how to estimate?\nTopics: What are word-embeddings? When and how can we use them? What? Topic models again? Is this still a bag of words?\n\n[GMB] - Chapter 8.\n[SLP] Chapter 6, “Vector Semantics and Embeddings.”\nMeyer, David. How Exactly Does Word2Vec Work?\nSpirling and Rodriguez, Word embeddings: What works, what doesn’t, and how to tell the difference for applied research.\n\n\n\nWeek 9: Word Embeddings: Social Science Applications\n\nApplied Papers:\n\nRodman, E., 2020. A Timely Intervention: Tracking the Changing Meanings of Political Concepts with Word Vectors. Political Analysis, 28(1), pp.87-111.\nGennaro, Gloria, and Elliott Ash. “Emotion and reason in political language.” The Economic Journal 132, no. 643 (2022): 1037-1059.\nRheault, Ludovic, and Christopher Cochrane. “Word embeddings for the analysis of ideological placement in parliamentary corpora.” Political Analysis 28, no. 1 (2020): 112-133.\nAustin C. Kozlowski, Austin C., Matt Taddy, and James A. Evans. 2019. “The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings.” American Sociological Review 84, no. 5: 905–49. https://doi.org/10.1177/0003122419877135.\nGarg, Nikhil, Londa Schiebinger, Dan Jurafsky and James Zou. 2018. “Word embeddings quantify 100 years of gender and ethnic stereotypes.” Proceedings of the National Academy of Sciences 115(16):E3635–E3644.\n\nProblem set 3 Assigned\n\n\n\nWeek 10: Using Text to Measure Ideology - Scaling\nTopics: What are scaling models and what can they tell us? Can we represent politicians/users ideology using text?\n\nApplied Papers:\n\nLaver, Michael, Kenneth Benoit, and John Garry. 2003. “Extracting Policy Positions from Political Texts Using Words as Data”. American Political Science Review. 97, 2, 311-331\nSlapin, Jonathan and Sven-Oliver Prokschk. 2008. “A Scaling Model for Estimating Time-Series Party Positions from Texts.” American Journal of Political Science. 52, 3 705-722\nRheault, Ludovic, and Christopher Cochrane. “Word embeddings for the analysis of ideological placement in parliamentary corpora.” Political Analysis 28, no. 1 (2020): 112-133.\nAruguete, Natalia, Ernesto Calvo, and Tiago Ventura. “News by popular demand: Ideological congruence, issue salience, and media reputation in news sharing.” The International Journal of Press/Politics 28, no. 3 (2023): 558-579.\nIzumi, Mauricio Y., and Danilo B. Medeiros. “Government and opposition in legislative speechmaking: using text-as-data to estimate Brazilian political parties’ policy positions.” Latin American Politics and Society 63, no. 1 (2021): 145-164.\n\n\n\n\nWeek 11: Replication Class II: Students’ Presentation\n\n\nWeek 12: Large Language Models: Theory and Fine-tuning a Transformers-based model (Inviter Speaker: Dr. Sebastian Vallejo)\nTopics: We will learn about the Transformers architecture, attention, and the encoder-coder infrastructure.\n\n[SLP] - Chapter 10.\nJay Alammar. 2018. “The Illustrated Transformer.” https://jalammar.github.io/illustratedtransformer/\nVaswani, A., et al. (2017). Attention is all you need. Advances in neural information processing systems, 30;\nTimoneda and Vera, BERT, RoBERTa or DeBERTa? Comparing Performance Across Transformer Models in Political Science Text, Forthcoming Journal of Politics.\n\n\n\nWeek 13: Large Language Models: Outsourcing Applications\n\nApplied Papers: We will see some social science application of LLMs chatbots. Can we use ChatGPT to perform zero-shot classification tasks? What are the concerns of these applications?\n\nWu, Patrick Y., Joshua A. Tucker, Jonathan Nagler, and Solomon Messing. “Large language models can be used to estimate the ideologies of politicians in a zero-shot learning setting.” arXiv preprint arXiv:2303.12057 (2023).\nRathje, Steve, Dan-Mircea Mirea, Ilia Sucholutsky, Raja Marjieh, Claire Robertson, and Jay J. Van Bavel. GPT is an effective tool for multilingual psychological text analysis. (2023).\nDavidson, Thomas: Start Generating: Harnessing Generative Artificial Intelligence for Sociological Research, PrePrint\nBisbee, James, Joshua Clinton, Cassy Dorff, Brenton Kenkel, and Jennifer Larson. 2023. “Synthetic Replacements for Human Survey Data? the Perils of Large Language Models.” SocArXiv. May 4.\n\n\n\n\nWeek 14: Final Projects: Students Presentation"
  },
  {
    "objectID": "syllabus.html#course-requirements",
    "href": "syllabus.html#course-requirements",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Course Requirements",
    "text": "Course Requirements\n\n\n\nAssignment\nPercentage of Grade\n\n\n\n\nParticipation/Attendance\n10%\n\n\nProblem Sets\n20%\n\n\nReplication Exercises\n30%\n\n\nFinal Project\n40%\n\n\n\nParticipation and Attendance (10%):\nData science is an cooperative endeavor, and it’s crucial to view your fellow classmates as valuable assets rather than rivals. Your performance in the following aspects will be considered when assessing this part of your grade:\n\nActive involvement during class sessions, fostering a dynamic learning environment.\nContributions made to your group’s ultimate project.\nAssisting classmates by addressing problem set queries through GitHub issues. Supporting your peers will enhance your evaluation in terms of teamwork and engagement\nAssisting classmates with slack questions, sharing interesting materials on slack, asking question, and anything that provides healthy contributtions to the course.\n\nProblem Sets (20%):\nYou will have a week to complete your assignments\nStudents will be assigned three problem sets over the course of the semesters. While you are encouraged to discuss the problem sets with your peers and/or consult online resources, the finished product must be your own work. The goal of the assignment is to reinforce the student’s comprehension of the materials covered in each section.\nThe problems sets will assess your ability to apply the concepts to data that is substantially messier, and problems that are substantially more difficult, than the ones in the coding discussion in class.\nI will distribute the assignment through a mix of canvas and github. The assignments can be in the form of a Jupyter Notebook (.ipynb) or Quarto (.qmd). Students must submit completed assignments as a rendered .html file and the corresponding source code (.ipynb or .qmd).\nThe assignments will be graded in accuracy and quality of the programming style. For instance, our grading team will be looking at:\n\n\nall code must run;\n\n\nsolutions should be readable\n\n\nCode should be thoroughly commented (the Professor/TA should be able to understand the codes purpose by reading the comment),\nCoding solutions should be broken up into individual code chunks in Jupyter/R Markdown notebooks, not clumped together into one large code chunk (See examples in class or reach out to the TA/Professor if this is unclear),\nEach student defined function must contain a doc string explaining what the function does, each input argument, and what the function returns;\n\n\nCommentary, responses, and/or solutions should all be written in Markdown and explain sufficiently the outpus.\n\n\nAll solutions must be completed in Python.\n\n\nThe follow schedule lays out when each assignment will be assigned.\n\n\n\nAssignment\nDate Assigned\nDate Due\n\n\n\n\nNo. 1\nWeek 4\nBefore EOD of Week 5’s class\n\n\nNo. 2\nWeek 7\nBefore EOD of Week 8’s class\n\n\nNo. 3\nWeek 9\nBefore EOD of Week 10’s class\n\n\n\nReplication Exercises (30%)\nReplication exercises are adapted from Gary King’s work here and here. Replication consists in the process of repeating a research study using the original data or brining new data to the conversation. Replicability is crucial for the advancement of knowledge and the credibility of scientific inquiry.\nFor our purposes, replication exercises will work as a educational tool. A common say in science is that you just learn a new skill/methods when you use in your own work. Since we do not have time to write three papers during a semester, we will take advantage of published work with open available datasets and code for us to work on replication exercises.\nYou will work in pairs for this assignment. Your partner will be randomly assigned. You will repeat this exercise twice throughout the course. This is a stylized step-by-step of this exercise:\n\nStep 1: finding a paper to replicate\n\nBy the end of the week 2 and week 7, you should select an article from the syllabus to be replicated by you.\nThe first replication exercise should consider articles from weeks 2 to week 5, and the second from the remaining of the class.\n\nStep 2: Acquiring the Data\n\nMost research articles are published with open data rules. This means their data and code are often available on github, or on harvard dataverse. Your first task is to find the data and code from these articles.\nIf your articles does not have the data and code, you should:\n\nPolitely contact the authors of the article and ask for the replication materials\nIf you don’t get response, select another article.\n\n\nStep 3: Presentation\n\nFor weeks 6 and 11, you will do a presentation of your replication efforts.\nThe presentation should have the following sections:\n\nIntroduction: introduction summarizing the article.\nMethods: data used in the article\nResults: the results you were able to replicate\nDifferences: any differences between your results and the authors’\nAutopsy of the replication: what worked and what did not work\nExtension: what would you do different if you were to write this article today? Where would you innovate?\n\n\nStep 4: Replication Repository\n\nBy Friday EOD of each replication week, you should share with me and all your colleagues your replication report. The replication report should be:\n\na github repo with a well-detailed readme. See an model here: https://github.com/TiagoVentura/winning_plosone\nyour presentation as a pdf\nthe code used in the replication as a notebook (Markdown or Jupyter)\na report with maximum of 5 pages (it is fine if you do less than that) summarizing the replication process, with emphasis on three sections of your presentation: Differences, Autopsy and Extension.\n\n\n\nIn addition to following the requirements above, the replication exercises will also be graded in accuracy and quality of the programming style. For instance, our grading team will be looking at:\n\n\nall code must run;\n\n\nsolutions should be readable\n\n\nCode should be thoroughly commented (the Professor/TA should be able to understand the codes purpose by reading the comment),\nCoding solutions should be broken up into individual code chunks in Jupyter/R Markdown notebooks, not clumped together into one large code chunk (See examples in class or reach out to the TA/Professor if this is unclear),\nEach student defined function must contain a doc string explaining what the function does, each input argument, and what the function returns;\n\n\nCommentary, responses, and/or solutions should all be written in Markdown and explain sufficiently the outpus.\n\n\n\nFinal Project (40%): Data science is an applied field and the DSPP is particularly geared towards providing students the tools to make policy and substantive contributtions using data and recent computational developments. In this sense, it is fundamental that you understand how to conduct a complete analysis from collecting data, to cleaning and analyzing it, to presenting your findings. For this reason, a considerable part of your grade will come from a an independent data science project, applying concepts learned throughout the course.\nThe project is composed of three parts:\n\na 2 page project proposal: (which should be discussed and approved by me)\nan in-class presentation,\nA 10-page project report.\n\nDue dates and breakdowns for the project are as follows:\n\n\n\n\n\n\n\n\n\nRequirement\nDue\nLength\nPercentage\n\n\n\n\nProject Proposal\nEOD Friday Week 9\n2 pages\n5%\n\n\nPresentation\nWeek 14\n10-15 minutes\n10%\n\n\nProject Report\nWednesday Week 15\n10 pages\n25%\n\n\n\nImportant notes about the final project\n\nFor the project proposal, you need to schedule a 30min with me at least a week before the due date. For this meeting, I expect you to send me a draft of your ideas. We will do the group assignment and start scheduling meetings by week 4, I will share with you a calendar invite to organize our meetings.\nFor the presentation, You will have 10-15 minutes in our last class of the semester to present you project.\nTake the final project seriously. After you finish your Masters, in any path you take, you will need to show concrete examples of your portfolio. This is a good opportunity to start building it.\nYour groups will be randomly assigned.\n\nSubmission of the Final Project\nThe end product should be a github repository that contains:\n\nThe raw source data you used for the project. If the data is too large for GitHub, talk with me, and we will find a solution\nYour proposal\nA README for the repository that, for each file, describes in detail:\n\nInputs to the file: e.g., raw data; a file containing credentials needed to access an API\nWhat the file does: describe major transformations.\nOutput: if the file produces any outputs (e.g., a cleaned dataset; a figure or graph).\nA set of code files that transform that data into a form usable to answer the question you have posed in your descriptive research proposal.\nYour final 10 pages report (I will share a template later in the semester)\n\n\nOf course, no commits after the due date will be considered in the assessment.\n\nGrading\nCourse grades will be determined according to the following scale:\n\n\n\nLetter\nRange\n\n\n\n\nA\n95% – 100%\n\n\nA-\n91% – 94%\n\n\nB+\n87% – 90%\n\n\nB\n84% – 86%\n\n\nB-\n80% – 83%\n\n\nC\n70% – 79%\n\n\nF\n&lt; 70%\n\n\n\nGrades may be curved if there are no students receiving A’s on the non-curved grading scale.\nLate problem sets will be penalized a letter grade per day.\n\n\nCommunication\n\nClass-relevant and/or coding-related questions, Slack is the preferred method of communication. Please use the general or the relevant channel for these questions.\nFor private questions concerning the class, email is the preferred method of communication. All email messages must originate from your Georgetown University email account(s). Please email the professor directly rather than through the Canvas messaging system.\nI will try my best to respond to all emails/slack questions within 24 hours of being sent during a weekday. I will not respond to emails/slack sent late Friday (after 5:00 pm) or during the weekend until Monday (9:00 am). Please plan accordingly if you have questions regarding current or upcoming assignments.\nOnly reach out to the professor or teaching assistant regarding a technical question, error, or issue after you made a good faith effort to debugging/isolate your problem prior to reaching out. Learning how to search for help online is a important skill for data scientists."
  },
  {
    "objectID": "syllabus.html#electronic-devices",
    "href": "syllabus.html#electronic-devices",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Electronic Devices",
    "text": "Electronic Devices\nWhen meeting in-person: the use of laptops, tablets, or other mobile devices is permitted only for class-related work. Audio and video recording is not allowed unless prior approval is given by the professor. Please mute all electronic devices during class."
  },
  {
    "objectID": "syllabus.html#georgetown-policies",
    "href": "syllabus.html#georgetown-policies",
    "title": "Syllabus: PPOL 6801 - Text as Data: Computational Linguistics",
    "section": "Georgetown Policies",
    "text": "Georgetown Policies\n\nDisability\nIf you believe you have a disability, then you should contact the Academic Resource Center (arc@georgetown.edu) for further information. The Center is located in the Leavey Center, Suite 335 (202-687-8354). The Academic Resource Center is the campus office responsible for reviewing documentation provided by students with disabilities and for determining reasonable accommodations in accordance with the Americans with Disabilities Act (ASA) and University policies. For more information, go to http://academicsupport.georgetown.edu/disability/\n\n\nImportant Academic Policies and Academic Integrity\nMcCourt School students are expected to uphold the academic policies set forth by Georgetown University and the Graduate School of Arts and Sciences. Students should therefore familiarize themselves with all the rules, regulations, and procedures relevant to their pursuit of a Graduate School degree. The policies are located at: http://grad.georgetown.edu/academics/policies/\nApplied to this course, while I encourage collaboration on assignments and use of resources like StackOverflow, the problem sets will ask you to list who you worked on the problem set with and cite StackOverflow if it is the direct source of a code snippet.\n\nChatGPT\nIn the last year, the world was inundated with popularization of Large Language Models, particularly the easy use of ChatGPT. I see ChatGPT as Google on steroids, so I assume ChatGPT will be part of your daily work in this course, and it is part of my work as a researcher.\nThat being said, ChatGPT does not replace your training as a data scientist. If you are using ChatGPT instead of learning, I consider you are cheating in the course. And most importantly, you are wasting your time and resources. So that’s our policy for using LLMs models in class:\n\nDo not copy the responses from chatgpt – a lot of them are wrong or will just not run on your computer.\nUse chatgpt as a auxiliary source.\nIf your entire homework comes straight from chatgpt, I will consider it plagiarism.\nIf you use chatgpt, I ask you to mention on your code how chatgpt worked for you.\n\n\n\n\nStatement on Sexual Misconduct\nGeorgetown University and its faculty are committed to supporting survivors and those impacted by sexual misconduct, which includes sexual assault, sexual harassment, relationship violence, and stalking. Georgetown requires faculty members, unless otherwise designated as confidential, to report all disclosures of sexual misconduct to the University Title IX Coordinator or a Deputy Title IX Coordinator. If you disclose an incident of sexual misconduct to a professor in or outside of the classroom (with the exception of disclosures in papers), that faculty member must report the incident to the Title IX Coordinator, or Deputy Title IX Coordinator. The coordinator will, in turn, reach out to the student to provide support, resources, and the option to meet. [Please note that the student is not required to meet with the Title IX coordinator.]. More information about reporting options and resources can be found on the Sexual Misconduct\nWebsite: https://sexualassault.georgetown.edu/resourcecenter\nIf you would prefer to speak to someone confidentially, Georgetown has a number of fully confidential professional resources that can provide support and assistance. These resources include: Health Education Services for Sexual Assault Response and Prevention: confidential email: sarp[at]georgetown.edu\nCounseling and Psychiatric Services (CAPS): 202.687.6985 or after hours, call (833) 960-3006 to reach Fonemed, a telehealth service; individuals may ask for the on-call CAPS clinician\nMore information about reporting options and resources can be found on the Sexual Misconduct Website.\n\n\nProvost’s Policy on Religious Observances\nGeorgetown University promotes respect for all religions. Any student who is unable to attend classes or to participate in any examination, presentation, or assignment on a given day because of the observance of a major religious holiday or related travel shall be excused and provided with the opportunity to make up, without unreasonable burden, any work that has been missed for this reason and shall not in any other way be penalized for the absence or rescheduled work. Students will remain responsible for all assigned work. Students should notify professors in writing at the beginning of the semester of religious observances that conflict with their classes. The Office of the Provost, in consultation with Campus Ministry and the Registrar, will publish, before classes begin for a given term, a list of major religious holidays likely to affect Georgetown students. The Provost and the Main Campus Executive Faculty encourage faculty to accommodate students whose bona fide religious observances in other ways impede normal participation in a course. Students who cannot be accommodated should discuss the matter with an advising dean."
  },
  {
    "objectID": "slides/week_01_intro.html#overview-of-tad-methods",
    "href": "slides/week_01_intro.html#overview-of-tad-methods",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Overview of TAD Methods",
    "text": "Overview of TAD Methods\n\nDescriptive inference: how to convert text to matrices, vector space model, bag-of-words, dissimilarity measures, diversity, complexity, style.\nSupervised techniques: dictionaries, classication, scaling, machine learning approaches.\nUnsupervised techniques: clustering, topic models, embeddings.\nSpecial topics: Word embeddings and Large Language Models."
  },
  {
    "objectID": "slides/week_01_intro.html",
    "href": "slides/week_01_intro.html",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "",
    "text": "Introduction (me)\nMotivation for Computational Linguistics\n\nDigital information age\nPrinciples of Computational Linguistics.\nWhat this course is not.\nExamples of models and applications for this course\n\nIntroductions (you)\nClass Logistics ( + 10 min for you to read through the syllabus)\nQ&A\nAcquiring text in the web (Jupyter notebooks for scrapping)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessor Tiago Ventura (he/him)\n\nAssistant Professor at McCourt School.\nPolitical Science Ph.D.\nPostdoc at Center for Social Media and Politics - NYU.\nResearcher at Twitter.\n\nSome Projects I am involved\n\nGlobal Social Media Deactivation.\nEffects of WhatsApp on Elections in the Global South.\nAI and Misinformation in 2024 elections.\nPanels of voter files and twitter users.\n\nOutside of work, I enjoy watching soccer, reading sci-fi and running"
  },
  {
    "objectID": "slides/week_02.html#highlight-content-that-your-reader-give-special-consideration-or-attention.",
    "href": "slides/week_02.html#highlight-content-that-your-reader-give-special-consideration-or-attention.",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "highlight content that your reader give special consideration or attention.",
    "text": "highlight content that your reader give special consideration or attention."
  },
  {
    "objectID": "index.html#credits",
    "href": "index.html#credits",
    "title": "PPOL 6801: Text as Data - Computational Linguistics",
    "section": "Credits",
    "text": "Credits\nTo build this course, I used materials from Arthur Spirling Text-as-Data Class at NYU, and lab materials from various TA’s for his course, Pablo Barbera’s Computational Social Science Seminar seminar, Brandon Stewart, Alex Siegel, Chris Bail, Sebastian Vallejo, among others. Their lessons and inspiration are spread throughout all the materials of the course. Thanks!"
  },
  {
    "objectID": "slides/week_02.html#visualizing-vector-space-model",
    "href": "slides/week_02.html#visualizing-vector-space-model",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Visualizing Vector Space Model",
    "text": "Visualizing Vector Space Model\n\n\n\nDoocuments\n\n\nDocument 1 = “yes yes yes no no no”\nDocument 2 = “no no yes no no no”"
  },
  {
    "objectID": "slides/week_02.html#outline",
    "href": "slides/week_02.html#outline",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Outline",
    "text": "Outline\n\n\nChallenges of working with text\nDefining a corpus and selecting documents\nUnit of analysis\nReducing complexity (Denny & Spirling’s article)\nBag-of-Word, Vector model representation and Document-Feature Matrix\nApplication (Ban et. al.’s paper)"
  },
  {
    "objectID": "slides/week_02.html#text-analysis-workflow",
    "href": "slides/week_02.html#text-analysis-workflow",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Text Analysis Workflow",
    "text": "Text Analysis Workflow\nAcquire textual data:\n\nExisting corpora; scraped data; digitized text\n\n\nMap Documents to a numerical representation M\n\nBag-of-words (sparse vectors)\nEmbeddings (dense vectors)\nReduce noise, capture signal\n\n\n\nMap M to predicted values \\(V^{*}\\) of unknown outcomes V\n\nDescriptive Analysis\nClassify documents into unknown categories ~ unsupervised/discovery\nClassify documents into known categories ~ supervised learning\nScale documents on latent dimension:\n\n\n\nUse \\(V^{*}\\) in subsequent analysis with other data sources\n\nThis is where social science happens!"
  },
  {
    "objectID": "slides/week_02.html#challenges-i-outcomes-in-the-latent-space",
    "href": "slides/week_02.html#challenges-i-outcomes-in-the-latent-space",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenges I: Outcomes in the Latent Space",
    "text": "Challenges I: Outcomes in the Latent Space\nIn most social science applications of text as data, we are trying to make an inference about a latent variable\n\nLatent variable: we cannot observe directly but try to identify with statistical and theorethical assumptions.\nExamples: ideology, sentiment, political stance, propensity of someone to turnout\n\n\nTraditional social science: mapping between observed and latent/theorethical concepts are easier.\n\nWe observe/measure country macroeconomic variables, collect survey responses, see how politicians vote.\nIn text, we only observe the words. Much harder to identify the latent concepts."
  },
  {
    "objectID": "slides/week_02.html#challenges-ii-text-is-an-unstructure-data-source",
    "href": "slides/week_02.html#challenges-ii-text-is-an-unstructure-data-source",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenges II: Text is an unstructure data source",
    "text": "Challenges II: Text is an unstructure data source"
  },
  {
    "objectID": "slides/week_02.html#challenge-iii-text-is-high-dimensional",
    "href": "slides/week_02.html#challenge-iii-text-is-high-dimensional",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenge III: Text is High-Dimensional",
    "text": "Challenge III: Text is High-Dimensional\nFrom Gentzkow et al 2017:\n\nsample of documents, each \\(n_L\\) words long, drawn from vocabulary of \\(n_V\\) words.\nThe unique representation of each document has dimension \\(n_{V}^{n_L}\\) .\n\ne.g., a sample of 30-word (\\(n_L\\)) Twitter messages using only the one thousand most common words in the English language\nDimensionality = \\(1000^{30}\\)\nAs a matrix: \\(M^{1000}_{n_tweets}\\)\n\nMost of what you learned in statistics so far does not equip you to deal with this curse of dimensionality."
  },
  {
    "objectID": "slides/week_02.html#vector-space-model",
    "href": "slides/week_02.html#vector-space-model",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "5. Vector Space Model",
    "text": "5. Vector Space Model\nTo represent documents as numbers, we will the vector space model representation:\n\na document \\(D_i\\) is represented as a collection of features \\(W\\) (words, tokens, n-grams..)\nEach feature \\(w_i\\) can be place in a real line, then a document \\(D_i\\) is a point in a \\(W\\) dimensional space\n\n\nImagine the sentence below: “If that is a joke, I love it. If not, can’t wait to unpack that with you later.”\n\nSorted Vocabulary =(a, can’t, i, if, is, it, joke, later, love, not, that, to, unpack, wait, with, you”)\nFeature Representation = (1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1)\nFeatures will typically be the n-gram (mostly unigram) frequencies of the tokens in the document, or some function of those frequencies\n\n\n\nNow each document is now a vector (vector space model)\n\nstacking these vectors will give you our workhose representation for text: Document Feature Matrix"
  },
  {
    "objectID": "slides/week_02.html#from-text-to-numbers-document-feature-matrix",
    "href": "slides/week_02.html#from-text-to-numbers-document-feature-matrix",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "From Text to Numbers: Document-Feature Matrix",
    "text": "From Text to Numbers: Document-Feature Matrix"
  },
  {
    "objectID": "slides/week_02.html#quick-exercise",
    "href": "slides/week_02.html#quick-exercise",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Quick Exercise",
    "text": "Quick Exercise\nWhat is the vector representation of this sentence? Give me the vocabulary and the feature representation. Remove any punctuation.\n \n“That’s just what translation is, I think. That’s all speaking is. Listening to the other and trying to see past your own biases to glimpse what they’re trying to say.”"
  },
  {
    "objectID": "slides/week_02.html#if-you-are-curious",
    "href": "slides/week_02.html#if-you-are-curious",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "If you are curious …",
    "text": "If you are curious …"
  },
  {
    "objectID": "slides/week_02.html#from-text-to-numbers",
    "href": "slides/week_02.html#from-text-to-numbers",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "From Text to Numbers",
    "text": "From Text to Numbers"
  },
  {
    "objectID": "slides/week_02.html#denny-spirling-2018",
    "href": "slides/week_02.html#denny-spirling-2018",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Denny & Spirling, 2018",
    "text": "Denny & Spirling, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nStarting point: No rigorous way to compare results across different pre-processing steps. Adapting recommendations from supervised learning tasks.\n\nUnsupervised vs Supervised Learning?\nWhat is their solution? (no math needed!)\nToo much work? Substantive knowledge out of the table?"
  },
  {
    "objectID": "slides/week_02.html#document-feature-matrix",
    "href": "slides/week_02.html#document-feature-matrix",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "6. Document-Feature Matrix",
    "text": "6. Document-Feature Matrix\n\n\n\n\n\n\n\n\n\n\n\nSource: Arthur Spirling TAD Class"
  },
  {
    "objectID": "slides/week_02.html#challenge-i-text-is-high-dimensional",
    "href": "slides/week_02.html#challenge-i-text-is-high-dimensional",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenge I: Text is High-Dimensional",
    "text": "Challenge I: Text is High-Dimensional\nFrom Gentzkow et al 2017:\n\nsample of documents, each \\(n_L\\) words long, drawn from vocabulary of \\(n_V\\) words.\nThe unique representation of each document has dimension \\(n_{V}^{n_L}\\) .\n\ne.g., a sample of 30-word (\\(n_L\\)) Twitter messages using only the one thousand most common words in the English language\nDimensionality = \\(1000^{30}\\)\nAs a matrix: \\(M^{1000}_{n_tweets}\\)"
  },
  {
    "objectID": "slides/week_02.html#challenge-ii-text-is-an-unstructure-data-source",
    "href": "slides/week_02.html#challenge-ii-text-is-an-unstructure-data-source",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenge II: Text is an unstructure data source",
    "text": "Challenge II: Text is an unstructure data source"
  },
  {
    "objectID": "slides/week_02.html#challenges-iii-outcomes-live-in-the-latent-space",
    "href": "slides/week_02.html#challenges-iii-outcomes-live-in-the-latent-space",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Challenges III: Outcomes live in the Latent Space",
    "text": "Challenges III: Outcomes live in the Latent Space\nIn most social science applications of text as data, we are trying to make an inference about a latent variable\n\nLatent variable: we cannot observe directly but try to identify with statistical and theorethical assumptions.\nExamples: ideology, sentiment, political stance, propensity of someone to turnout\n\n\nTraditional social science: mapping between observed and latent/theoretical concepts is easier.\n\nWe observe/measure country macroeconomic variables, collect survey responses, see how politicians vote.\nIn text, we only observe the words. Much harder to identify the latent concepts."
  },
  {
    "objectID": "slides/week_02.html#class-today",
    "href": "slides/week_02.html#class-today",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Class today",
    "text": "Class today\nToday:\n\nCover techniques to reduce complexity from text data using a set of pre-processing steps ~ Challenge I\nHow to represent text as numbers using the vector space model ~ Challenge II\nStarting next week we will deal more with inference and modeling latent parameters using text ~ Challenge III"
  },
  {
    "objectID": "slides/week_02.html#reducing-complexity",
    "href": "slides/week_02.html#reducing-complexity",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "3. Reducing complexity",
    "text": "3. Reducing complexity\nLanguage is extraordinarily complex, and involves great subtlety and nuanced interpretation.\n\nWe simplify documents so that we can analyze/compared them:\n\nmakes the modeling problem much more tractable.\ncomplexity makes not much difference in topic identification or simple prediction tasks (sentiment analysis, for example)\n\nthe degree to which one simplifees is dependent on the particular task at hand.\n\nDenny and Spirling (2019) ~ check sensitivity."
  },
  {
    "objectID": "slides/week_02.html#denny-spirling-2018-1",
    "href": "slides/week_02.html#denny-spirling-2018-1",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Denny & Spirling, 2018",
    "text": "Denny & Spirling, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nStarting point: No rigorous way to compare results across different pre-processing steps. Adapting recommendations from supervised learning tasks.\n\nUnsupervised vs Supervised Learning?\nWhat is their solution? (no math needed!)\nToo much work? Substantive knowledge out of the table?\n\n\n\n\n\nText-as-Data"
  },
  {
    "objectID": "slides/week_02.html#some-concepts",
    "href": "slides/week_02.html#some-concepts",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Some Concepts",
    "text": "Some Concepts"
  },
  {
    "objectID": "slides/week_02.html#ban-et.-al.-2019-how-newspapers-reveal-political-power.",
    "href": "slides/week_02.html#ban-et.-al.-2019-how-newspapers-reveal-political-power.",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Ban et. al. 2019, How Newspapers Reveal Political Power.",
    "text": "Ban et. al. 2019, How Newspapers Reveal Political Power.\n\n\n\n\n\n\n\n\n \n\nPurely descriptive\nSimple measure just by counting words.\nTheorethically-driven: measure that capture a theorethically relevant concept.\n\n\n\\[\n\\small \\text{Coverage of Mayor}_{it} = \\frac{\\text{Mayor}_{it}}{\\text{Mayor}_{it} + \\text{City Manager}_{it} + \\text{City Council}_{it}}\n\\]\n\n\n\n\n\nText-as-Data"
  },
  {
    "objectID": "slides/week_02.html#defining-a-document",
    "href": "slides/week_02.html#defining-a-document",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Defining a Document",
    "text": "Defining a Document"
  },
  {
    "objectID": "slides/week_02.html#reducing-complexity-theory",
    "href": "slides/week_02.html#reducing-complexity-theory",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Reducing complexity: theory",
    "text": "Reducing complexity: theory\nLanguage is extraordinarily complex, and involves great subtlety and nuanced interpretation.\n\nWe simplify documents so that we can analyze/compared them:\n\nmakes the modeling problem much more tractable.\ncomplexity makes not much difference in topic identification or simple prediction tasks (sentiment analysis, for example)\n\nthe degree to which one simplifees is dependent on the particular task at hand.\n\nDenny and Spirling (2019) ~ check sensitivity."
  },
  {
    "objectID": "slides/week_02.html#reducing-complexity-steps",
    "href": "slides/week_02.html#reducing-complexity-steps",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Reducing complexity: steps",
    "text": "Reducing complexity: steps\n\nTokenization: What does constitute a feature?\nRemove `superfulous’ material: HTML tags, punctuation, numbers, lower case and stop words\nMap words to equivalence forms: stemming and lemmatization\nDiscard less useful features for your task at hand: functional words, highly frequent or rare words\nDiscard word order: Bag-of-Words Assumption"
  },
  {
    "objectID": "slides/week_02.html#tokenization",
    "href": "slides/week_02.html#tokenization",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Tokenization",
    "text": "Tokenization\n\nA first step in any text analysis task is to break documents in meaningful units of analysis (tokens)\nTokens are often words for most tasks. A simple tokenizer uses white space marks to split documents in tokens.\nTokenizer may vary [across tasks]{.red}:\n\nTwiter specific tokenizer ~ keep hashtags, for example.\n\nMay also vary across languages, in which white space is not a good marker to split text into tokens\n\nchinese and japanese\n\nCertain tokens, even in english, make more sense together than separate (“White House”, “United States”). These are collocations\n\nstatistical testing for collocations ~ PMI(a, b) = log(p(a,b)/p(a)*p(b))"
  },
  {
    "objectID": "slides/week_02.html#stop-words",
    "href": "slides/week_02.html#stop-words",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Stop Words",
    "text": "Stop Words\n\nThere are certain words that serve as linguistic connectors (`function words’) which we can remove.\n\n( the, it, if, a, for, from, at, on, in, be )\n\nAdd noise to the document. Discard them, focus on signal, meaningful words.\nMost TAD packages have a pre-selected list of stopwords. You can add more given you substantive knowledge (more about this later)\nUsually not important for unsupervised and mostly supervised tasks, but might matter for authorship detection.\n\nFederalist Papers, example. Stop words give away writing styles."
  },
  {
    "objectID": "slides/week_02.html#equivalence-mapping",
    "href": "slides/week_02.html#equivalence-mapping",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Equivalence mapping",
    "text": "Equivalence mapping\nReduce dimensionality even further!\n\nDifferent forms of words (family, families, familial), or words which are similar in concept (bureaucratic, bureaucrat, bureaucratization) that refer to same basic token/concept.\nuse algorithms to map these variation to a equivalent form:\n\nstemming: chop the end of the words: family, families, familiar ~ famili\nlemmatization: condition on part of speech\n\nbetter (adj) ~ good\nleaves (noun) ~ leaf\nleaves (verb) ~ leave\n\n\nAll [TAD/NLP packages[{.red}] offer easy applications for these algorithms."
  },
  {
    "objectID": "slides/week_02.html#task-specific-cleaning",
    "href": "slides/week_02.html#task-specific-cleaning",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Task-Specific Cleaning",
    "text": "Task-Specific Cleaning"
  },
  {
    "objectID": "slides/week_02.html#bag-of-words-assumption",
    "href": "slides/week_02.html#bag-of-words-assumption",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "4. Bag-of-Words Assumption",
    "text": "4. Bag-of-Words Assumption\nNow we have pre-processed our data. So we simplify it even further:\n\nBag-of-Words Assumption: the order in which words appear does not matter.\n\nIgnore order\nBut keep multiplicity, we still consider frequency of words\n\n\n\nHow could this possible work:\n\nit might note: you need validation\ncentral tendency in text: some words are enough to topic detection, classificaiton, measures of similarity, and distance, for example.\nhumans in the loop: expertise knowledge help you figure it out subtle relationships between words and outcomes"
  },
  {
    "objectID": "slides/week_02.html#can-we-preserve-the-word-order-another-pre-processing-decision",
    "href": "slides/week_02.html#can-we-preserve-the-word-order-another-pre-processing-decision",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Can we preserve the word order? (another pre-processing decision)",
    "text": "Can we preserve the word order? (another pre-processing decision)\nYes\n\nwe might retaining word order using n-grams.\n\nWhite House, Bill Gates, State Department, Middle East\nwe think some important subtlety of expression is lost: negation perhaps\n\nI want coffee, not tea might be interpreted very diferently without word order.\n\n\ncan use [n-grams], which are (sometimes contiguous) sequences of two (bigrams) or three (trigrams) tokens.\nThis makes computations considerably more complex. We can pick some n-grams to keep but not all:\n\n\\(PMI_{a,b} = log \\frac{p_{a,b}}{p_a \\cdot p_b}\\)\n\nif p(a,b)=0 ~ log (0) = -inf\nif p(a,b)=p(a)p(b) ~ log(1) = 0\nif p(a,b)&lt;p(a)p(b) ~ log(0&lt;x&lt;1) &lt; 0\nif p(a,b)&gt;p(a)p(b) ~ log(x&gt;1) &gt; 0"
  },
  {
    "objectID": "slides/week_02.html#complete-example",
    "href": "slides/week_02.html#complete-example",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Complete Example",
    "text": "Complete Example\n\n\n\nText\n\n\nWe use a new dataset containing nearly 50 million historical newspaper pages from 2,700 local US newspapers over the years 1877–1977. We define and discuss a measure of power we develop based on observed word frequencies, and we validate it through a series of analyses. Overall, we find that the relative coverage of political actors and of political offices is a strong indicator of political power for the cases we study\n\n\n\n\n\n\n\nAfter pre-processing\n\n\nuse new dataset contain near 50 million historical newspaper pag 2700 local u newspaper year 18771977 define discus measure power develop bas observ word frequenc validate ser analys overall find relat coverage political actor political offic strong indicator political power cas study"
  },
  {
    "objectID": "slides/week_02.html#other-steps-functional-words-highly-frequent-or-rare-words",
    "href": "slides/week_02.html#other-steps-functional-words-highly-frequent-or-rare-words",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Other steps: functional words, highly frequent or rare words",
    "text": "Other steps: functional words, highly frequent or rare words\nSome other commons steps, which are highly dependent on your contextual knowledge, are:\n\ndiscard functional words: for example, when working with congressional speeches, remove representative, congress, session, etc...\nremove highly frequent words: words that appear in all documents carry very little meaning for most supervised and unsupervised tasks ~ no clustering and not discrimination.\nremove rare frequent words: same logic as above, no signal. Commong practice, words appear less 5% fo documents."
  },
  {
    "objectID": "slides/week_02.html#visualizing-vector-space-model-1",
    "href": "slides/week_02.html#visualizing-vector-space-model-1",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Visualizing Vector Space Model",
    "text": "Visualizing Vector Space Model\nIn the vector space, we can use geometry to build well-defined comparison measures between the documents (more about this next week)"
  },
  {
    "objectID": "slides/week_02.html#learning-goals",
    "href": "slides/week_02.html#learning-goals",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Learning goals",
    "text": "Learning goals\nToday:\n\nCover techniques to reduce complexity from text data using a set of pre-processing steps ~ Challenge I\nHow to represent text as numbers using the vector space model ~ Challenge II\nStarting next week we will deal more with inference and modeling latent parameters using text ~ Challenge III"
  },
  {
    "objectID": "slides/week_02.html#corpus-and-selecting-documents",
    "href": "slides/week_02.html#corpus-and-selecting-documents",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "1. Corpus and selecting documents",
    "text": "1. Corpus and selecting documents\n\nA corpus is (typically) a large set of texts or documents which we wish to analyze.\n\nif you can read them in an small amount of time, you should just do it, not TAD\n\nWhen selecting a corpus, we should consider how the corpus relates to our research question in two aspects:\n\nPopulation of interest: does the corpus allows us to make inferences about them?\nQuantity of interest: can we measure what we plan to?\nSampling Bias: documents are often sampled from a larger population. Are there concerns about sample selection bias?\n\nMost often we use these documents because they were available to us (custom made data). In these cases, considering the three questions above is even more important."
  },
  {
    "objectID": "slides/week_02.html#ventura-streaming-chats-2021",
    "href": "slides/week_02.html#ventura-streaming-chats-2021",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Ventura, Streaming Chats, 2021",
    "text": "Ventura, Streaming Chats, 2021\n\n\n\n\n\n\n\n\nKey components\n\n\nRQ: Measure quality of comments on streaming chat platforms during political debates\nPopulation of interest?\nQuantity of interest?\nSource of bias?"
  },
  {
    "objectID": "slides/week_02.html#ventura-et.-al.-streaming-chats-2021",
    "href": "slides/week_02.html#ventura-et.-al.-streaming-chats-2021",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "Ventura et. al., Streaming Chats, 2021",
    "text": "Ventura et. al., Streaming Chats, 2021\n\n\n\n\n\n\n\n\nKey components\n\n\nRQ: Measure quality of comments on streaming chat platforms during political debates\nPopulation of interest?\nQuantity of interest?\nSource of bias?"
  },
  {
    "objectID": "slides/week_02.html#unit-of-analysis",
    "href": "slides/week_02.html#unit-of-analysis",
    "title": "PPOL 6801 - Text as Data - Computational Linguistics",
    "section": "2. Unit of Analysis",
    "text": "2. Unit of Analysis\nAfter selecting your documents and converting them to a computer-friendly format, we must decide our unit of analysis\n\nentire document? sentence? paragraph? a larger group of documents?\n\n\nThree things to consider in making this decision:\n\nFeatures of your data and model fit\nYour research question\nIterative model\n\nswitching through different units of analysis has a low cost\nallows you to look at the data from a different angle\nprovide new insights to your research"
  }
]