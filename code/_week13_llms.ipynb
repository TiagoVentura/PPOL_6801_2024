{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad84a7f-6b1f-4176-9ffa-ce9746321367",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center> PPOL 6801 Text as Data <br><br> \n",
    "<font color='grey'> LLMs: Outsourcing Text-as-Data Tasks  <br><br>\n",
    "Tiago Ventura </center> <h1> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ccee9",
   "metadata": {},
   "source": [
    "### Outsourcing Text-as-Data Tasks to Generative Text-Based Models: GPT's API\n",
    "\n",
    "As you know, ChatGPT is an large language model (as we just saw) developed by OpenAI, based on the GPT architecture. The model was trained on a word-prediction task and it has blown the world by its capacity to engage in conversational interactions.\n",
    "\n",
    "You should be familiar with interacting with the ChatGPT tool to solve a variety of tasks. Here I will show you how to do that at scale, by using prompts to interact with the model via Open AI API. \n",
    "\n",
    "The whole process requires us to have access to the Open AI API which allow us to query continously the GPT models. Notice, this is not free. You pay for every query. In general, for small tasks, it is not super expensive. However, for tasks with millions of predictions, it can get expensive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94979247",
   "metadata": {},
   "source": [
    "## Tasks and Prompts\n",
    "\n",
    "Before we try to replicate the tasks behind the papers we read in class, let's see some simple tasks we can ask GPT models to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d620a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23826d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load api key\n",
    "# load library to get environmental files\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests \n",
    "\n",
    "\n",
    "# load keys from  environmental var\n",
    "load_dotenv() # .env file in cwd\n",
    "gpt_key = os.environ.get(\"gpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07ba069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple query\n",
    "\n",
    "# define headers\n",
    "headers = {\n",
    "        \"Authorization\": f\"Bearer {gpt_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "# define gpt model\n",
    "question = \"Please, tell me more about the Data Science and Public Policy Program at Georgetown's McCourt School\"\n",
    "\n",
    "data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# send a post request\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers)\n",
    "# convert to json\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c77cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Data Science and Public Policy Program at Georgetown's McCourt School is a unique program that combines the fields of data science and public policy. The program is designed to equip students with the skills and knowledge needed to use data science to solve complex policy problems.\\n\\nThe program is interdisciplinary in nature, drawing on expertise from the fields of statistics, computer science, economics, and political science. Students in the program learn how to collect, analyze, and interpret data to inform policy decisions.\\n\\nThe curriculum includes courses in data science, statistics, machine learning, and policy analysis. Students also have the opportunity to work on real-world policy projects, collaborating with government agencies, non-profit organizations, and private sector companies.\\n\\nGraduates of the program are well-equipped to pursue careers in a variety of fields, including government, non-profit organizations, and the private sector. They are able to use data science to inform policy decisions and drive positive change in their communities.\\n\\nOverall, the Data Science and Public Policy Program at Georgetown's McCourt School is an innovative and exciting program that is helping to shape the future of public policy.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb308c4",
   "metadata": {},
   "source": [
    "## Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c8cf2",
   "metadata": {},
   "source": [
    "In Rathje et. al., we saw the use of GPT models for sentiment classification using zero-shot prompts. \n",
    "\n",
    "This is a super simple task. Let's see some code below on how to go about it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11a578a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the ChatGPT API\n",
    "def hey_chatGPT(question_text, api_key):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question_text}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers, timeout=5)\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e386a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_likes_count</th>\n",
       "      <th>comment_message</th>\n",
       "      <th>attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2718</td>\n",
       "      <td>10156654608505103_10156669038490103</td>\n",
       "      <td>0</td>\n",
       "      <td>MY BLOG GREAT INFO SPREAD IT FAR AND WIDE, THE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1633</td>\n",
       "      <td>10154720750470839_10154721001020839</td>\n",
       "      <td>3</td>\n",
       "      <td>If firearms are so scary, why are you protecte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2122</td>\n",
       "      <td>921123364588415_921438624556889</td>\n",
       "      <td>0</td>\n",
       "      <td>Senator, please learn the difference between \"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>935623009801759_935712999792760</td>\n",
       "      <td>0</td>\n",
       "      <td>Please get funding for agriculture.  We have s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>10153067712751682_10153068186251682</td>\n",
       "      <td>0</td>\n",
       "      <td>And you let him get away with the man caused c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           comment_id  comment_likes_count  \\\n",
       "0   2718  10156654608505103_10156669038490103                    0   \n",
       "1   1633  10154720750470839_10154721001020839                    3   \n",
       "2   2122      921123364588415_921438624556889                    0   \n",
       "3   1000      935623009801759_935712999792760                    0   \n",
       "4     29  10153067712751682_10153068186251682                    0   \n",
       "\n",
       "                                     comment_message  attacks  \n",
       "0  MY BLOG GREAT INFO SPREAD IT FAR AND WIDE, THE...        0  \n",
       "1  If firearms are so scary, why are you protecte...        1  \n",
       "2  Senator, please learn the difference between \"...        0  \n",
       "3  Please get funding for agriculture.  We have s...        0  \n",
       "4  And you let him get away with the man caused c...        1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# let's open some twitter data\n",
    "pd_test = pd.read_csv(\"../data/incivility.csv\")\n",
    "\n",
    "# sample\n",
    "pd_test = pd_test.sample(n=10).reset_index()\n",
    "\n",
    "# see\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2eae6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "output = []\n",
    "# Run a loop over your dataset of reviews and prompt ChatGPT\n",
    "for i in range(len(pd_test)):\n",
    "    try: \n",
    "        print(i)\n",
    "        question = \"Is the sentiment of this text positive, neutral, or negative? \\\n",
    "        Answer only with a number: 1 if positive, 0 if neutralm and -1 if negative. \\\n",
    "        Here is the text: \"\n",
    "        text = pd_test.loc[i, \"comment_message\"]\n",
    "        full_question = question + str(text)\n",
    "        output.append(hey_chatGPT(full_question, gpt_key))\n",
    "    except:\n",
    "        output.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49fa7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output\n",
    "pd_test[\"sentiment\"]= output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db281386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     comment_message sentiment\n",
      "0  MY BLOG GREAT INFO SPREAD IT FAR AND WIDE, THE...         1\n",
      "1  If firearms are so scary, why are you protecte...        -1\n",
      "2  Senator, please learn the difference between \"...         0\n",
      "3  Please get funding for agriculture.  We have s...        -1\n",
      "4  And you let him get away with the man caused c...        -1\n",
      "5  We use our commissary regularly. It is more ex...         0\n",
      "6  Our congressman once again wasting taxpayer ti...        -1\n",
      "7  You and the Boehner lot are full of hot air. A...        -1\n",
      "8  They hate Obama because he is smart and black,...        -1\n",
      "9  I'm voting for Steven Stokes!!!  As Mario Isra...         1\n"
     ]
    }
   ],
   "source": [
    "# see\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(pd_test[[\"comment_message\", \"sentiment\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d8d88c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:MY BLOG GREAT INFO SPREAD IT FAR AND WIDE, THEY HATE IT, https://chemtrailsaremindcontrol.shutterfly.com/, VA DOCTOR EXPOSING VA CRIMES https://vimeo.com/channels/stopchemtrailsnow \n",
      "Sentiment: 1\n",
      "Text:If firearms are so scary, why are you protected by them 24/7? Why do you and these people view their lives as more important because you can buy an election? Because you have lobbyists that give you tons of money to buy them votes.   Why do you feel more important? Vote to rid all of capital hill of armed security if you want to be taken seriously. Vote to rid of armed protection for you. \n",
      "Sentiment: -1\n",
      "Text:Senator, please learn the difference between \"climate\" and \"weather.\" \n",
      "Sentiment: 0\n",
      "Text:Please get funding for agriculture.  We have several that will be losing their jobs at the end of September in the College of Agriculture at Auburn. \n",
      "Sentiment: -1\n",
      "Text:And you let him get away with the man caused climate change junk science. \n",
      "Sentiment: -1\n",
      "Text:We use our commissary regularly. It is more expensive to go out in town, even if the store does double coupons. \n",
      "Sentiment: 0\n",
      "Text:Our congressman once again wasting taxpayer time and money.   If he really cared about the safety of citizens he's make sure the immigration laws were upheld and he'd do something about the 3000 children murdered every day across the country. \n",
      "Sentiment: -1\n",
      "Text:You and the Boehner lot are full of hot air. All talk and no action... Spending us into extinction while forgetting Republican principles... \n",
      "Sentiment: -1\n",
      "Text:They hate Obama because he is smart and black, yet they love Ben Carson. They are evil and insane. \n",
      "Sentiment: -1\n",
      "Text:I'm voting for Steven Stokes!!!  As Mario Israel Vargas so aptly put it (below), \"Loretta Sanchez is an undemocratic Clinton pledged superdelegate. The same Clinton that deported women and children that came to America to run away from violence. No thank you!\" \n",
      "Sentiment: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pd_test)):\n",
    "    print(\"Text:\" + pd_test[\"comment_message\"][i] + \" \\nSentiment: \" + pd_test[\"sentiment\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379acb8",
   "metadata": {},
   "source": [
    "## Scaling via pair-wise comparison\n",
    "\n",
    "Now let's see how we can use GPT to do pairwise comparison. Notice, we saw in the paper that pairwise comparisons can be used as input for scaling models of ideology. But, this type of labeled data can be used for many different tasks, for example, readability and sophistication scores, as we saw earlier in the semester. \n",
    "\n",
    "Together with Lisa Signh and Leticia Bode, we are actually using a similar approach, but we human labelling, to understand levels of hummaness of social media content in the AI-Era. Next year, you can email me and I can show you some results!\n",
    "\n",
    "The code below was actually provided by Patrick Wu. So thanks to him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e3a3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring soma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from itertools import combinations\n",
    "from random import sample, choices\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03577359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a client to interact with the API\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=gpt_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b703c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd499e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "p: the prompt\n",
    "system_prompt: the system prompt. The default is what is used on the ChatGPT's web interface.\n",
    "temp: temperature parameter. 1.0 is the default (for GPT-3.5, temperature ranges from 0 to 2.0)\n",
    "request_timeout: the amount of time, in seconds, to timeout the function.\n",
    "'''\n",
    "def prompting_openai_comparison(p,\n",
    "                                system_prompt='You are ChatGPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-10-28',\n",
    "                                temp=1.0):\n",
    "  # times used to sleep; these values approximate exponential backoff\n",
    "    sleepy_times = [1, 2]\n",
    "\n",
    "    for i in range(len(sleepy_times)):\n",
    "        try:\n",
    "            response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                              messages=[{\"role\": \"system\", \n",
    "                                                         \"content\": system_prompt},\n",
    "                                                        {\"role\": \"user\", \n",
    "                                                         \"content\": p}],\n",
    "                                              temperature=0)\n",
    "            break\n",
    "        except:\n",
    "          # if OpenAI's API returns an error, this lets you know and backs off for the set time, determined using the sleepy_times list\n",
    "          print('uh oh, ' + str(sleepy_times[i]))\n",
    "          time.sleep(sleepy_times[i])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd4c97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of S116 members\n",
    "#!wget https://voteview.com/static/data/out/members/S116_members.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "916a1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('S116_members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e75d9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get an ordinary version of some members of the congress\n",
    "# Add \"ordinary\" versions of senators' names\n",
    "df['bioname_ordinary'] = ['Donald Trump',\n",
    "'Doug Jones',\n",
    "'Richard Shelby',\n",
    "'Lisa Murkowski',\n",
    "'Dan Sullivan',\n",
    "'Kyrsten Sinema',\n",
    "'Martha McSally',\n",
    "'Mark Kelly',\n",
    "'John Boozman',\n",
    "'Tom Cotton',\n",
    "'Kamala Harris',\n",
    "'Dianne Feinstein',\n",
    "'Cory Gardner',\n",
    "'Michael Bennet',\n",
    "'Chris Murphy',\n",
    "'Richard Blumenthal',\n",
    "'Tom Carper',\n",
    "'Chris Coons',\n",
    "'Marco Rubio',\n",
    "'Rick Scott',\n",
    "'Johnny Isakson',\n",
    "'David Perdue',\n",
    "'Kelly Loeffler',\n",
    "'Mazie Hirono',\n",
    "'Brian Schatz',\n",
    "'Mike Crapo',\n",
    "'James Risch',\n",
    "'Dick Durbin',\n",
    "'Tammy Duckworth',\n",
    "'Todd Young',\n",
    "'Mike Braun',\n",
    "'Chuck Grassley',\n",
    "'Joni Ernst',\n",
    "'Pat Roberts',\n",
    "'Jerry Moran',\n",
    "'Mitch McConnell',\n",
    "'Rand Paul',\n",
    "'Bill Cassidy',\n",
    "'John Kennedy',\n",
    "'Angus King',\n",
    "'Susan Collins',\n",
    "'Ben Cardin',\n",
    "'Chris Van Hollen',\n",
    "'Ed Markey',\n",
    "'Elizabeth Warren',\n",
    "'Gary Peters',\n",
    "'Debbie Stabenow',\n",
    "'Amy Klobuchar',\n",
    "'Tina Smith',\n",
    "'Roger Wicker',\n",
    "'Cindy Hyde-Smith',\n",
    "'Roy Blunt',\n",
    "'Josh Hawley',\n",
    "'Steve Daines',\n",
    "'Jon Tester',\n",
    "'Deb Fischer',\n",
    "'Ben Sasse',\n",
    "'Jacky Rosen',\n",
    "'Catherine Cortez Masto',\n",
    "'Jeanne Shaheen',\n",
    "'Maggie Hassan',\n",
    "'Bob Menendez',\n",
    "'Cory Booker',\n",
    "'Martin Heinrich',\n",
    "'Tom Udall',\n",
    "'Chuck Schumer',\n",
    "'Kirsten Gillibrand',\n",
    "'Richard Burr',\n",
    "'Thom Tillis',\n",
    "'Kevin Cramer',\n",
    "'John Hoeven',\n",
    "'Rob Portman',\n",
    "'Sherrod Brown',\n",
    "'Jim Inhofe',\n",
    "'James Lankford',\n",
    "'Ron Wyden',\n",
    "'Jeff Merkley',\n",
    "'Pat Toomey',\n",
    "'Bob Casey',\n",
    "'Jack Reed',\n",
    "'Sheldon Whitehouse',\n",
    "'Tim Scott',\n",
    "'Lindsey Graham',\n",
    "'John Thune',\n",
    "'Mike Rounds',\n",
    "'Marsha Blackburn',\n",
    "'Lamar Alexander',\n",
    "'John Cornyn',\n",
    "'Ted Cruz',\n",
    "'Mike Lee',\n",
    "'Mitt Romney',\n",
    "'Patrick Leahy',\n",
    "'Bernie Sanders',\n",
    "'Mark Warner',\n",
    "'Tim Kaine',\n",
    "'Maria Cantwell',\n",
    "'Patty Murray',\n",
    "'Shelley Moore Capito',\n",
    "'Joe Manchin',\n",
    "'Tammy Baldwin',\n",
    "'Ron Johnson',\n",
    "'John Barrasso',\n",
    "'Mike Enzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96ff8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Donald Trump\n",
    "df = df.iloc[1:,]\n",
    "\n",
    "# sample just a few\n",
    "df = df.sample(n=10).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac6b9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then get dictionaries that obtain the party and state for each senator by name\n",
    "names = list(df['bioname_ordinary'])\n",
    "state = list(df['state_abbrev'])\n",
    "party = ['R' if j==200 else 'D' if j==100 else 'I' for j in list(df['party_code'])]\n",
    "\n",
    "name_party_dict = {n: p for n,p in zip(names,party)}\n",
    "name_state_dict = {n: s for n,s in zip(names,state)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc3fbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function samples a total number of matchups per senator. this does not mean that each senator is limited to a max of sample_size matchups\n",
    "# it means each senator will appear in at least sample_size matchups\n",
    "def generate_pairwise_matchups(items, sample_size=20, seed_value=42):\n",
    "  random.seed(seed_value)\n",
    "\n",
    "  if sample_size >= len(items) or sample_size < 1:\n",
    "    raise ValueError(\"Sample size must be between 1 and one less than the total number of tweet IDs\")\n",
    "\n",
    "  all_matchups = []\n",
    "\n",
    "  # Generate all possible pairings\n",
    "  all_combinations = list(combinations(items, 2))\n",
    "\n",
    "  for i in items:\n",
    "    # Filter matchups containing the current tweet ID\n",
    "    relevant_matchups = [pair for pair in all_combinations if i in pair]\n",
    "\n",
    "    # Shuffle the matchups\n",
    "    random.shuffle(relevant_matchups)\n",
    "\n",
    "    # Sample from these matchups up to the specified sample size\n",
    "    all_matchups.extend(relevant_matchups[:sample_size])\n",
    "\n",
    "  return all_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9259709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = generate_pairwise_matchups(names, sample_size=1, seed_value=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0421939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matchups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc94ab8",
   "metadata": {},
   "source": [
    "Here, we note the direction of comparison. We have to use liberal and conservative differently in these prompts because, when comparing two Republicans, if I prompt ChatGPT with \"who is more liberal,\" it will often fail to answer this and reply that both senators are conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "736269ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "comparison_direction = []\n",
    "\n",
    "for j in matchups:\n",
    "    # D vs. D\n",
    "    if (name_party_dict[j[0]]=='D' or name_party_dict[j[0]]=='I') and (name_party_dict[j[1]]=='D' or name_party_dict[j[1]]=='I'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # D vs. R\n",
    "    elif (name_party_dict[j[0]]=='D' or name_party_dict[j[0]]=='I') and (name_party_dict[j[1]]=='R'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # R vs. D\n",
    "    elif (name_party_dict[j[0]]=='R') and (name_party_dict[j[1]]=='D' or name_party_dict[j[1]]=='I'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # R vs. R\n",
    "    elif (name_party_dict[j[0]]=='R') and (name_party_dict[j[1]]=='R'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more conservative: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('conservative')\n",
    "    else:\n",
    "        print('OH NO!')\n",
    "        break\n",
    "    prompts.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3a4fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the system prompt for the pairwise comparison.\n",
    "system_prompt = 'You are ChatGPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-09-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8c483c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEwBOLswBwjg",
    "outputId": "59ee1cb5-9966-45ef-d475-ca6ba00a4419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Based on past voting records and statements, which senator is more liberal: Dan Sullivan (R-AK) or Angus King (I-ME)?', 'Based on past voting records and statements, which senator is more conservative: Mike Lee (R-UT) or Bill Cassidy (R-LA)?', 'Based on past voting records and statements, which senator is more liberal: Tina Smith (D-MN) or Ron Wyden (D-OR)?', 'Based on past voting records and statements, which senator is more liberal: Ron Wyden (D-OR) or Ben Sasse (R-NE)?', 'Based on past voting records and statements, which senator is more liberal: Angus King (I-ME) or Jon Tester (D-MT)?', 'Based on past voting records and statements, which senator is more liberal: Tina Smith (D-MN) or Jon Tester (D-MT)?', 'Based on past voting records and statements, which senator is more liberal: Mike Lee (R-UT) or Mark Kelly (D-AZ)?', 'Based on past voting records and statements, which senator is more liberal: Mark Kelly (D-AZ) or Dianne Feinstein (D-CA)?', 'Based on past voting records and statements, which senator is more conservative: Dan Sullivan (R-AK) or Bill Cassidy (R-LA)?', 'Based on past voting records and statements, which senator is more conservative: Bill Cassidy (R-LA) or Ben Sasse (R-NE)?']\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ced31",
   "metadata": {
    "id": "jtheSOQ6-yck"
   },
   "source": [
    "Now we're finally ready to run the pairwise comparisons. We run it in parallel because it takes a very long time to run if you iterate one prompt at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a16e4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a container\n",
    "comparison_results = []\n",
    "\n",
    "# iterate\n",
    "for p in prompts:\n",
    "    results = prompting_openai_comparison(p, system_prompt, 1.0)\n",
    "    comparison_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "74de65f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9F1aFfX1E4eJ2HrFUdK4NfQ1NqZnx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of my last knowledge update in September 2021, Angus King, an Independent Senator from Maine, is generally considered more liberal than Dan Sullivan, a Republican Senator from Alaska. Angus King caucuses with the Democrats and tends to align with them on many key issues, while Dan Sullivan typically aligns with the Republican Party on most issues.\\n\\nHowever, political positions and affiliations can evolve, so I recommend checking more recent sources to get the most up-to-date information on the voting records and statements of these senators to determine their current positions accurately.', role='assistant', function_call=None, tool_calls=None))], created=1713368035, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=110, prompt_tokens=85, total_tokens=195))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at it \n",
    "comparison_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "677c00e7",
   "metadata": {
    "id": "If7vQcBIEKb6"
   },
   "outputs": [],
   "source": [
    "# Extract the text answer from ChatGPT responses\n",
    "def get_text_from_chatgpt(responses):\n",
    "  return [responses[i].choices[0].message.content for i in range(len(responses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c444d3a",
   "metadata": {
    "id": "4BqEETdHEUhI"
   },
   "outputs": [],
   "source": [
    "comparisons_text = get_text_from_chatgpt(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3db795e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb6h_yBnEZHC",
    "outputId": "3bab01e4-e01e-46f5-8137-c657d1e2d864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in September 2021, Angus King, an Independent Senator from Maine, is generally considered more liberal than Dan Sullivan, a Republican Senator from Alaska. Angus King caucuses with the Democrats and tends to align with them on many key issues, while Dan Sullivan typically aligns with the Republican Party on most issues.\n",
      "\n",
      "However, political positions and affiliations can evolve, so I recommend checking more recent sources to get the most up-to-date information on the voting records and statements of these senators to determine their current positions accurately.\n"
     ]
    }
   ],
   "source": [
    "# This is what a pairwise comparison looks like.\n",
    "print(comparisons_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c328a",
   "metadata": {
    "id": "VCvcOOqsDq_j"
   },
   "source": [
    "Now we need to extract the answers from our comparisons. We'll append our answers from before and ask ChatGPT to extract the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1863fe63",
   "metadata": {
    "id": "8BFHJoMxDnCp"
   },
   "outputs": [],
   "source": [
    "extracting_answer_prompt = []\n",
    "\n",
    "for i in range(len(comparisons_text)):\n",
    "    if comparison_direction[i]=='liberal':\n",
    "        sent = 'Text: \"' + comparisons_text[i] + '\"\\n\\nIn the above Text, who is described to be the more liberal, more progressive, or less conservative senator: ' + matchups[i][0] + ' or ' + matchups[i][1] + '? Return only the full name without party affiliation or state information. If one senator is described as more conservative, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more liberal, more progressive, less conservative, more conservative, or more moderate, reply with \"Tie.\"'\n",
    "    elif comparison_direction[i]=='conservative':\n",
    "        sent = 'Text: \"' + comparisons_text[i] + '\"\\n\\nIn the above Text, who is described to be the more conservative or less liberal senator: ' + matchups[i][0] + ' or ' + matchups[i][1] + '? Return only the full name without party affiliation or state information. If one senator is described as more liberal, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more conservative, less liberal, more liberal, or more moderate, reply with \"Tie.\"'\n",
    "    extracting_answer_prompt.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a3a8668",
   "metadata": {
    "id": "Ip_xDa7bDya1"
   },
   "outputs": [],
   "source": [
    "system_prompt_extraction = 'You are reading a Text and extracting information from it according to the prompt. Follow the directions exactly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bedb7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text: \"As of my last knowledge update in September 2021, Angus King, an Independent Senator from Maine, is generally considered more liberal than Dan Sullivan, a Republican Senator from Alaska. Angus King caucuses with the Democrats and tends to align with them on many key issues, while Dan Sullivan typically aligns with the Republican Party on most issues.\\n\\nHowever, political positions and affiliations can evolve, so I recommend checking more recent sources to get the most up-to-date information on the voting records and statements of these senators to determine their current positions accurately.\"\\n\\nIn the above Text, who is described to be the more liberal, more progressive, or less conservative senator: Dan Sullivan or Angus King? Return only the full name without party affiliation or state information. If one senator is described as more conservative, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more liberal, more progressive, less conservative, more conservative, or more moderate, reply with \"Tie.\"'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see this!\n",
    "extracting_answer_prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bad6fdef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7rxmUVQEolE",
    "outputId": "dd5d69cb-701a-435c-ec5c-081af4d22d54"
   },
   "outputs": [],
   "source": [
    "# create a container\n",
    "extraction = []\n",
    "\n",
    "# iterate\n",
    "for p in extracting_answer_prompt:\n",
    "    results = prompting_openai_comparison(p, system_prompt, 1.0)\n",
    "    extraction.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5686f8c4",
   "metadata": {
    "id": "jFqjJJ_8Eybm"
   },
   "outputs": [],
   "source": [
    "extraction_text = get_text_from_chatgpt(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "061e55a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angus King',\n",
       " 'Mike Lee',\n",
       " 'Ron Wyden',\n",
       " 'Ron Wyden',\n",
       " 'Angus King',\n",
       " 'Tina Smith',\n",
       " 'Mark Kelly',\n",
       " 'Mark Kelly',\n",
       " 'Tie.',\n",
       " 'Tie.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c8cb2a4",
   "metadata": {
    "id": "2ZBuHNk5E9jp"
   },
   "outputs": [],
   "source": [
    "# this function simply removes the period at the sentences\n",
    "def remove_period(sentence):\n",
    "    if sentence.endswith('.'):\n",
    "        sentence = sentence[:-1]\n",
    "    return sentence\n",
    "\n",
    "# this function simply removes the 'Senator ' prefix. For example, it returns \"Dianne Feinstein\" if the input text is \"Senator Dianne Feinstein\"\n",
    "def remove_senator_prefix(input_string):\n",
    "    if input_string.startswith(\"Senator \"):\n",
    "        return input_string[8:]\n",
    "    else:\n",
    "        return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c39f3b1",
   "metadata": {
    "id": "VQB2YpreE8A5"
   },
   "outputs": [],
   "source": [
    "extraction_text = [remove_period(t) for t in extraction_text]\n",
    "extraction_text = [remove_senator_prefix(t) for t in extraction_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "616223ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zF94uPOFGQK",
    "outputId": "0087d2b5-50d2-44f3-9c62-9e35cb2bfac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angus King\n"
     ]
    }
   ],
   "source": [
    "print(extraction_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6311aa",
   "metadata": {
    "id": "gq4wIEduFPsq"
   },
   "source": [
    "We then use a function to check that every extraction was correct. Sometimes it will still not correctly extract the answer, which means we have to step in and manually fix it. If the function prints nothing, great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6500be5",
   "metadata": {
    "id": "0KLnXKWUFgQR"
   },
   "source": [
    "This step will make the final dataframe with the resultant matchups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22478c46",
   "metadata": {
    "id": "pZ7bARJeFX2a"
   },
   "outputs": [],
   "source": [
    "def make_final_df(matchups, chatgpt_answers, final_answers, comparison_direction):\n",
    "    sen1 = [j[0] for j in matchups]\n",
    "    sen2 = [j[1] for j in matchups]\n",
    "\n",
    "    matchup_results = pd.DataFrame({'matchup': matchups,\n",
    "                                    'senator1': sen1,\n",
    "                                    'senator2': sen2,\n",
    "                                    'chatgpt_response': chatgpt_answers,\n",
    "                                    'final_answers': final_answers,\n",
    "                                    'comparison_direction': comparison_direction})\n",
    "\n",
    "    opposite = []\n",
    "    sen1_win = []\n",
    "    sen2_win = []\n",
    "\n",
    "    for i in range(len(matchup_results['matchup'])):\n",
    "        if matchup_results['comparison_direction'][i]=='liberal':\n",
    "            if matchup_results['final_answers'][i]==matchup_results['senator1'][i]:\n",
    "                sen1_win.append(0.0)\n",
    "                sen2_win.append(1.0)\n",
    "            elif matchup_results['final_answers'][i]==matchup_results['senator2'][i]:\n",
    "                sen1_win.append(1.0)\n",
    "                sen2_win.append(0.0)\n",
    "            elif matchup_results['final_answers'][i]=='Tie':\n",
    "                sen1_win.append(0.5)\n",
    "                sen2_win.append(0.5)\n",
    "        elif matchup_results['comparison_direction'][i]=='conservative':\n",
    "            if matchup_results['final_answers'][i]==matchup_results['senator1'][i]:\n",
    "                sen1_win.append(1.0)\n",
    "                sen2_win.append(0.0)\n",
    "            elif matchup_results['final_answers'][i]==matchup_results['senator2'][i]:\n",
    "                sen1_win.append(0.0)\n",
    "                sen2_win.append(1.0)\n",
    "            elif matchup_results['final_answers'][i]=='Tie':\n",
    "                sen1_win.append(0.5)\n",
    "                sen2_win.append(0.5)\n",
    "        else:\n",
    "            print(str(i) + ' is a defective outcome')\n",
    "\n",
    "    matchup_results['win1'] = sen1_win\n",
    "    matchup_results['win2'] = sen2_win\n",
    "\n",
    "    return matchup_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "565ebe1a",
   "metadata": {
    "id": "Au6wNzobFks2"
   },
   "outputs": [],
   "source": [
    "final_df = make_final_df(matchups=matchups,\n",
    "                         chatgpt_answers=comparisons_text,\n",
    "                         final_answers=extraction_text,\n",
    "                         comparison_direction=comparison_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f046048e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "mWP71OiXFnRZ",
    "outputId": "2fb2b438-12fc-4e6b-b4bb-35a86713d80a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchup</th>\n",
       "      <th>senator1</th>\n",
       "      <th>senator2</th>\n",
       "      <th>chatgpt_response</th>\n",
       "      <th>final_answers</th>\n",
       "      <th>comparison_direction</th>\n",
       "      <th>win1</th>\n",
       "      <th>win2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Dan Sullivan, Angus King)</td>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>Angus King</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Angus King</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Mike Lee, Bill Cassidy)</td>\n",
       "      <td>Mike Lee</td>\n",
       "      <td>Bill Cassidy</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Mike Lee</td>\n",
       "      <td>conservative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Tina Smith, Ron Wyden)</td>\n",
       "      <td>Tina Smith</td>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Ron Wyden, Ben Sasse)</td>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>Ben Sasse</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Ron Wyden</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Angus King, Jon Tester)</td>\n",
       "      <td>Angus King</td>\n",
       "      <td>Jon Tester</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Angus King</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Tina Smith, Jon Tester)</td>\n",
       "      <td>Tina Smith</td>\n",
       "      <td>Jon Tester</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Tina Smith</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Mike Lee, Mark Kelly)</td>\n",
       "      <td>Mike Lee</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Mark Kelly, Dianne Feinstein)</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>Dianne Feinstein</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Dan Sullivan, Bill Cassidy)</td>\n",
       "      <td>Dan Sullivan</td>\n",
       "      <td>Bill Cassidy</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Tie</td>\n",
       "      <td>conservative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Bill Cassidy, Ben Sasse)</td>\n",
       "      <td>Bill Cassidy</td>\n",
       "      <td>Ben Sasse</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Tie</td>\n",
       "      <td>conservative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          matchup      senator1          senator2  \\\n",
       "0      (Dan Sullivan, Angus King)  Dan Sullivan        Angus King   \n",
       "1        (Mike Lee, Bill Cassidy)      Mike Lee      Bill Cassidy   \n",
       "2         (Tina Smith, Ron Wyden)    Tina Smith         Ron Wyden   \n",
       "3          (Ron Wyden, Ben Sasse)     Ron Wyden         Ben Sasse   \n",
       "4        (Angus King, Jon Tester)    Angus King        Jon Tester   \n",
       "5        (Tina Smith, Jon Tester)    Tina Smith        Jon Tester   \n",
       "6          (Mike Lee, Mark Kelly)      Mike Lee        Mark Kelly   \n",
       "7  (Mark Kelly, Dianne Feinstein)    Mark Kelly  Dianne Feinstein   \n",
       "8    (Dan Sullivan, Bill Cassidy)  Dan Sullivan      Bill Cassidy   \n",
       "9       (Bill Cassidy, Ben Sasse)  Bill Cassidy         Ben Sasse   \n",
       "\n",
       "                                    chatgpt_response final_answers  \\\n",
       "0  As of my last knowledge update in September 20...    Angus King   \n",
       "1  As of my last knowledge update in September 20...      Mike Lee   \n",
       "2  As of my last knowledge update in September 20...     Ron Wyden   \n",
       "3  As of my last knowledge update in September 20...     Ron Wyden   \n",
       "4  As of my last knowledge update in September 20...    Angus King   \n",
       "5  As of my last knowledge update in September 20...    Tina Smith   \n",
       "6  As of my last knowledge update in September 20...    Mark Kelly   \n",
       "7  As of my last knowledge update in September 20...    Mark Kelly   \n",
       "8  As of my last knowledge update in September 20...           Tie   \n",
       "9  As of my last knowledge update in September 20...           Tie   \n",
       "\n",
       "  comparison_direction  win1  win2  \n",
       "0              liberal   1.0   0.0  \n",
       "1         conservative   1.0   0.0  \n",
       "2              liberal   1.0   0.0  \n",
       "3              liberal   0.0   1.0  \n",
       "4              liberal   0.0   1.0  \n",
       "5              liberal   0.0   1.0  \n",
       "6              liberal   1.0   0.0  \n",
       "7              liberal   0.0   1.0  \n",
       "8         conservative   0.5   0.5  \n",
       "9         conservative   0.5   0.5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b770ad4",
   "metadata": {},
   "source": [
    "From here would just need to go the R to do the Bradley Terry model. Happy to share code about this as well, but that would be too much for today!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c513cfd",
   "metadata": {},
   "source": [
    "## Generating survey responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b489f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the ChatGPT API\n",
    "def survey_chatGPT(profile, prompt, api_key):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0.2,\n",
    "        \"messages\": [{\"role\": \"system\", \n",
    "                      \"content\": profile}, \n",
    "                    {\"role\":\"user\", \n",
    "                    \"content\":prompt}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers, timeout=5)\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4daaf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_profile(age, race, gender, educ, inc, pid):\n",
    "    profile = \"You are a \" + str(age) + \" year old \" + race + \" \"+ gender + \" with a \" + educ + \", earning $\" + inc + \" per year . \" + \"You are a registered \" + pid + \" living in the USA in 2019. \"\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0c2fdd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a 55 year old latino female with a post-graduate, earning $100,000 per year . You are a registered Democrat living in the USA in 2019. '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one profile\n",
    "profile = gen_profile(55, \"latino\", \"female\", \"post-graduate\", \"100,000\", \"Democrat\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddfbe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Provide responses from this person's perspective.\\n\"\\\n",
    "         \"Use only knowledge about politics that they would have.\\n\"\\\n",
    "         \"Format the output as a csv table with the following format:\\n\"\\\n",
    "         \"group, thermometer\\n\"\\\n",
    "         \"The following questions ask about individuals' feelings \"\\\n",
    "         \"toward different groups.\\n\"\\\n",
    "         \"Responses should be given on a scale from 0 (meaning cold \"\\\n",
    "         \"feelings) to 100 (meaning warm feelings).\\n\"\\\n",
    "         \"Ratings between 50 degrees and 100 degrees mean that\\n\"\\\n",
    "         \"you feel favorable and warm toward the group. Ratings \"\\\n",
    "         \"between 0\\n\"\\\n",
    "         \"degrees and 50 degrees mean that you don't feel \"\\\n",
    "         \"favorable toward\\n\"\\\n",
    "         \"the group and that you don't care too much for that \"\\\n",
    "         \"group. You\\n\"\\\n",
    "         \"would rate the group at the 50 degree mark if you don't feel\\n\"\\\n",
    "         \"particularly warm or cold toward the group.\\n\"\\\n",
    "         \"How do you feel toward the following groups?\\n\"\\\n",
    "         \"The Democratic Party?\\n\"\\\n",
    "         \"The Republican Party?\\n\"\\\n",
    "         \"Democrats?\\n\"\\\n",
    "         \"Republicans?\\n\"\\\n",
    "         \"Black Americans?\\n\"\\\n",
    "         \"White Americans?\\n\"\\\n",
    "         \"Hispanic Americans?\\n\"\\\n",
    "         \"Asian Americans?\\n\"\\\n",
    "         \"Muslims?\\n\"\\\n",
    "         \"Christians?\\n\"\\\n",
    "         \"Immigrants?\\n\"\\\n",
    "         \"Gays and Lesbians?\\n\"\\\n",
    "         \"Jews?\\n\"\\\n",
    "         \"Liberals?\\n\"\\\n",
    "         \"Conservatives?\\n\"\\\n",
    "         \"Women?\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b7c20df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9F1cl9BpvJ6VkSjMpUmsGatiUexja', 'object': 'chat.completion', 'created': 1713368191, 'model': 'gpt-3.5-turbo-0301', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'group,thermometer\\nThe Democratic Party,90\\nThe Republican Party,20\\nDemocrats,85\\nRepublicans,25\\nBlack Americans,80\\nWhite Americans,70\\nHispanic Americans,85\\nAsian Americans,80\\nMuslims,70\\nChristians,75\\nImmigrants,90\\nGays and Lesbians,85\\nJews,80\\nLiberals,90\\nConservatives,20\\nWomen,90'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 262, 'completion_tokens': 89, 'total_tokens': 351}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "# get an output\n",
    "output = survey_chatGPT(profile, prompt, gpt_key)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4c8b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9F1cl9BpvJ6VkSjMpUmsGatiUexja',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1713368191,\n",
       " 'model': 'gpt-3.5-turbo-0301',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'group,thermometer\\nThe Democratic Party,90\\nThe Republican Party,20\\nDemocrats,85\\nRepublicans,25\\nBlack Americans,80\\nWhite Americans,70\\nHispanic Americans,85\\nAsian Americans,80\\nMuslims,70\\nChristians,75\\nImmigrants,90\\nGays and Lesbians,85\\nJews,80\\nLiberals,90\\nConservatives,20\\nWomen,90'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 262, 'completion_tokens': 89, 'total_tokens': 351},\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ddfde85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'group,thermometer\\nThe Democratic Party,90\\nThe Republican Party,20\\nDemocrats,85\\nRepublicans,25\\nBlack Americans,80\\nWhite Americans,70\\nHispanic Americans,85\\nAsian Americans,80\\nMuslims,70\\nChristians,75\\nImmigrants,90\\nGays and Lesbians,85\\nJews,80\\nLiberals,90\\nConservatives,20\\nWomen,90'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = output[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3599e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>thermometer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Democratic Party</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Republican Party</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrats</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republicans</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Americans</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White Americans</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hispanic Americans</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asian Americans</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Muslims</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Christians</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Immigrants</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gays and Lesbians</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jews</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Liberals</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Conservatives</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Women</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   group thermometer\n",
       "0   The Democratic Party          90\n",
       "1   The Republican Party          20\n",
       "2              Democrats          85\n",
       "3            Republicans          25\n",
       "4        Black Americans          80\n",
       "5        White Americans          70\n",
       "6     Hispanic Americans          85\n",
       "7        Asian Americans          80\n",
       "8                Muslims          70\n",
       "9             Christians          75\n",
       "10            Immigrants          90\n",
       "11     Gays and Lesbians          85\n",
       "12                  Jews          80\n",
       "13              Liberals          90\n",
       "14         Conservatives          20\n",
       "15                 Women          90"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get response\n",
    "response = output[\"choices\"][0][\"message\"]['content']\n",
    "\n",
    "# clean\n",
    "lines = response.split('\\n')\n",
    "data = [line.split(',') for line in lines]\n",
    "\n",
    "# build data frame \n",
    "pd.DataFrame(data[1:], columns=data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed58023",
   "metadata": {
    "id": "OJrWeMmZlV5P"
   },
   "source": [
    "# Using Meta's LLaMa2\n",
    "\n",
    "Instead of using Open AI models, we can (and I think we should) work with open source LLM models, such as LLaMa2 from Meta. You can use the model after getting access to it on Hugging face!\n",
    "\n",
    "I suggest you to run this on a Google Colab with GPU! Let's just see a simple example here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "995535da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzmcNRhnl3tt",
    "outputId": "26549a84-0939-4f4b-c6f0-8a85dba109ed"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a312fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbd4a7d2316410086001df8b912ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05812f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYjAkRzToC8E",
    "outputId": "4d02b0cf-0cb8-41e4-8c31-4064ad2db1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/tb186/anaconda3/lib/python3.11/site-packages (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (2.4.0.dev20240416)\n",
      "Requirement already satisfied: huggingface-hub in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/tb186/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73d1aab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609,
     "referenced_widgets": [
      "4cbcdb3cfcdf4c46b854df86247d6c6b",
      "76d618452b624b509498271ab007481c",
      "92d8673b14244778999225f887887f8d",
      "176745fc5906477ebf3e612bbdb1caa6",
      "7fd2b04cb82347ddabc2b1ff1198f1a1",
      "6b950c69314f4dde811168bca454470d",
      "3002d62fa0bc44af98a68d75e564e277",
      "63453d598ece42a0bc2a38e9408a24c6",
      "4d8424a29ecb453db35a0a50490ea679",
      "94b93a6a23674b5c9dfb7c0d0cfe4ddc",
      "d0af2661af884a56806840d9fa204efd",
      "38d79d8a668f4b17833aa89c76eb2b3c",
      "4806a79d4ab943eca27528cfcfd039a6",
      "1e413b059182429fbcef3bcd8abfeb0b",
      "8fbdee67b91f4a3bb6ccfec6b229461f",
      "9eb68e04518b4d0fb982e5ee3fd0d6e3",
      "afc1ee8496de442e94e1c00235b39df1",
      "82f61ce852074244b44ce21985703a17",
      "40ba6a38890a48a2a71f8ec63216782f",
      "949f5f479170421a9ba0de747f9c7389",
      "e5d508eeba7a478189080af01c43cf1d",
      "cbadb104f68646219b51eac0209d0c7f",
      "d779419dd3d64a47ad7568b4a7ea0314",
      "d011f9a50d91472e8da4f2a05097eccf",
      "d8ab95b01cc8401f9980514167846b16",
      "c1aba4fdd74542f8a90ca8e92ba101a1",
      "aa50659235cf4104b6cd9a23c77b924e",
      "203ccb14e7d948169f49e4dfcb1ba320",
      "82cf63b4a3e14ab8a05a602f04d89f7f",
      "c50751e33a4c4d038da536d706060ac3",
      "f2791d104d2f4d93a9addf6fad4626cf",
      "225e9725eddc4c449fdeb5bd322c793b",
      "af108c59ff724f17a4c00940aa56d6f0",
      "6ace03bc6a884121933ccc77056b38c2",
      "d661be16531a4f959c9eeb009d2962d6",
      "95af691a08f34e06b4ce4cd51ab7fcc2",
      "c79f132dc3644278a8f64c068f891efb",
      "18472defd8d44701a8b7bce0d227289d",
      "1c428e71554f4ad185ef8eeef4d25c80",
      "d3122caf3316416cb7cb3acc8d076e34",
      "bf076d5f6c8c44f6a5827295528d2079",
      "1b3ca02340324b80b3f9e740644d57d8",
      "bf324084742e4c8a93a44712598f6c53",
      "aff8d13b49eb47cd9923569bbbe327c1",
      "67d94c1e9cab48c2bc243d19652a0d30",
      "f3b9ac75997f47a487b210fa7e41e17e",
      "73ae036843b846e59e0cb58cacbd9188",
      "7ef0d0f462d044319ab80e40e1a741e4",
      "1907cbb018194e5599b5350ea7df3164",
      "3979977dec5f4099a661941b6f867705",
      "65a606af203245488f46c8e99103e987",
      "9618bd4489dc4f33b8257a94230c33e0",
      "cee93bc6484a4e59acfa86fe77d8ec70",
      "4b8926a9576a4725bd2ccd79fa59aba4",
      "07fb8b6af64041d9acdb4a5a17b4155d",
      "a30814c087fe4eba822b00da6d85b0d0",
      "1f261a8528e44cf3aee7f847cc32f1f8",
      "97735000fefa4c079a97f6a91b6380be",
      "54611321826b42e29b81dbfe3ce57985",
      "4d694afd5d2a45f6aa22551e8192335c",
      "55b6735e3e014c5fbf326d531ab29be8",
      "0475662c90b54b39bb932916c23bc2b6",
      "be71ca2a981340e3988538e5a6df65fb",
      "1f4b11e13470470991d7d385940bb9f4",
      "ee75f5a03ed74056a8b3a01c14498093",
      "06a08ec3cf92497e9c8fff2354f5db89",
      "40db8eb8a7f3443687a2b64a729e5db6",
      "652d6ce29d6a40e893ee0b04501b98c3",
      "432ca735926249358c252f50e6787f60",
      "15f3b5abc2cf4829bbba233dd8850694",
      "541f7e57737d40b8b6a7eb5f6a31da58",
      "ac8862a27d914b07add94e5e80ca4575",
      "c18d7aa1b6fc4a3b84a50ad2847cc642",
      "a86647978dbc41ba89d911a64dcca77a",
      "7197683b177748698e196fb8ba548a72",
      "1275f1f4eef649f98bd8350b653aac7a",
      "bbe4551e16544d9a8a264cdbee51215e",
      "90d0be5b047940b5bbf9689bd735063a",
      "1c551fb4ec8644b68019121a0cd0fa6b",
      "e94a34290c8f4789b7d34acfb8898bf9",
      "01c7642ff44f47538bf78f7f32df34cb",
      "113bac44686141558af23d789fe2946f",
      "810958f726944251ac7ef1cb1c259ea7",
      "20a4e52d59a04d4fb3468c975833bfc2",
      "da6fffc5aebf4586abd0b2e0ac460fed",
      "eab5ef56e9fe447c85085ba204ed2331",
      "d18dead40fb1479899be368e7a2cb858",
      "4393071b428e4f30bd18019db4562360",
      "7b3fcb3cb6f64eec8a86944f12ba1ce5",
      "a3fe102a563b4a4f9aa75333d9ffffe0",
      "f4f6369ff4ce404ba025fb74d885030d",
      "876534fb28fb41f2960e4ab94cb903c0",
      "5324fb96b84e4818a1548c31fdbd064c",
      "a628b5f018fc4e21b7ad7be87343637b",
      "a3e5358b036d4be9836cd22294c24e4a",
      "06884eff45194ae9aee2fe0b51ab2b19",
      "7ebcceb4723a413b9308d75c544206e7",
      "42acd6f75fe94e44a6e956e0bc488f4c",
      "7b7f018295c14dd9b052bd25d2dd589b",
      "53245232162f4e8297226e7543e56fdf",
      "2bab8c6ece2b4c0d8adde42bbd692978",
      "1007101f03cb406589c0de7e85a15b99",
      "0a3332d0dc0a40738f7d4afc7fa8ea7a",
      "1728a8dfe2d84768bc5c48801be116a5",
      "9fefa1d7328340bf84620a6f7e3fc285",
      "72cd87b71a7c4d7f954a748d904fe15b",
      "1324d9eea3f64815a4ca2fa74e6d89b5",
      "8f20e654197a4f9caeec695fa47c2897",
      "9a48df09a6b84530b4dd3d09583cc5d2",
      "ec32b8ee27024b949be79260ec4cb5c0",
      "df9b548bc30245b5b34f80650bd8737e",
      "a3e0f2e349bc471a8b583a4629206a1f",
      "2b891d82091548338bd3d8da6de09982",
      "a52392ba0c67434e8b7820557c177d13",
      "aa159a553a90490cb8a5240b4789305f",
      "3584bf0f3b944247a32c9714584ab298",
      "a4f0a87bcc044144bf643454ada1271f",
      "36c7facc7daf4bcbaac2cd227ceb199b",
      "babee5db6adc4801bd2c247df6bfe683",
      "823c7d0c08e7471c8da0197904b84c51",
      "a8fec212da8b44d1b452bf09116f423c"
     ]
    },
    "id": "2VQwzMMBmqoF",
    "outputId": "b9a83df0-a758-421d-d2a9-c69088445824"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57722f2a08e74a2b9f0c327025e0d9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\" # Calling the smallest model of 7 billion parameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# First time, download will take a bit (depending on connection). File is around 13GB.\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"mps\") # If you are using a Mac.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13860f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIDgsE8gqX1v",
    "outputId": "d7663f5b-78d1-46eb-bc6e-dba5fae89e4a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  You are not a voice for the people of Kansas.      You are a voice for the people of Washington, D.C. and New York City.      You are not a voice for the people of Kansas.      You are a voice for the people of the United States.      You are not a voice for the people of the United States.      You are a voice for the people of the world.      You are not a voice for the people of the world.      You are a voice for the people of the universe.      You are not a voice for the people of the universe.      You are a voice for the people of the cosmos.      You are not a voice for the people of the cosmos\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    \"Is the sentiment of this text positive, neutral, or negative? \\\n",
    "    Answer only with a number: 1 if positive, 0 if neutralm and -1 if negative. \\\n",
    "    Here is the text: Oh, Pat, you know it is about President Obama naming the Supreme Court Justice.\\\n",
    "    Don't drag your feet on this, and don't be an obstacle to yet another proposal by the President.  \\\n",
    "    You are way to old and removed from Kansas to be a voice for us. \",\n",
    "    do_sample=True, # this prevents the model from just picking the most likely word at every step greedily\n",
    "    top_k=1, # limit the number of words the model considers when decoding before randomly sampling from the word probabilities.\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=250, # what is the length of sequence we want?\n",
    "    return_full_text = False,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
