{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad84a7f-6b1f-4176-9ffa-ce9746321367",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center> PPOL 6801 Text as Data <br><br> \n",
    "<font color='grey'> LLMs: Outsourcing Text-as-Data Tasks  <br><br>\n",
    "Tiago Ventura </center> <h1> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ccee9",
   "metadata": {},
   "source": [
    "### Outsourcing Text-as-Data Tasks to Generative Text-Based Models: GPT's API\n",
    "\n",
    "As you know, ChatGPT is an large language model (as we just saw) developed by OpenAI, based on the GPT architecture. The model was trained on a word-prediction task and it has blown the world by its capacity to engage in conversational interactions.\n",
    "\n",
    "You should be familiar with interacting with the ChatGPT tool to solve a variety of tasks. Here I will show you how to do that at scale, by using prompts to interact with the model via Open AI API. \n",
    "\n",
    "The whole process requires us to have access to the Open AI API which allow us to query continously the GPT models. Notice, this is not free. You pay for every query. In general, for small tasks, it is not super expensive. However, for tasks with millions of predictions, it can get expensive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94979247",
   "metadata": {},
   "source": [
    "## Tasks and Prompts\n",
    "\n",
    "Before we try to replicate the tasks behind the papers we read in class, let's see some simple tasks we can ask GPT models to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d620a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23826d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load api key\n",
    "# load library to get environmental files\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests \n",
    "\n",
    "\n",
    "# load keys from  environmental var\n",
    "load_dotenv() # .env file in cwd\n",
    "gpt_key = os.environ.get(\"gpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07ba069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple query\n",
    "\n",
    "# define headers\n",
    "headers = {\n",
    "        \"Authorization\": f\"Bearer {gpt_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "# define gpt model\n",
    "question = \"Please, tell me more about the Data Science and Public Policy Program at Georgetown's McCourt School\"\n",
    "\n",
    "data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# send a post request\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers)\n",
    "# convert to json\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c77cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Data Science and Public Policy Program at Georgetown's McCourt School is a unique program that combines the fields of data science and public policy. The program is designed to equip students with the skills and knowledge needed to use data science to solve complex policy problems.\\n\\nThe program is interdisciplinary in nature, drawing on expertise from the fields of statistics, computer science, economics, and political science. Students in the program learn how to collect, analyze, and interpret data to inform policy decisions.\\n\\nThe curriculum includes courses in data science, statistics, machine learning, and policy analysis. Students also have the opportunity to work on real-world policy projects, collaborating with government agencies, non-profit organizations, and private sector companies.\\n\\nGraduates of the program are well-equipped to pursue careers in a variety of fields, including government, non-profit organizations, and the private sector. They are able to use data science to inform policy decisions and drive positive change in their communities.\\n\\nOverall, the Data Science and Public Policy Program at Georgetown's McCourt School is an innovative and exciting program that is helping to shape the future of public policy.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb308c4",
   "metadata": {},
   "source": [
    "## Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c8cf2",
   "metadata": {},
   "source": [
    "In Rathje et. al., we saw the use of GPT models for sentiment classification using zero-shot prompts. \n",
    "\n",
    "This is a super simple task. Let's see some code below on how to go about it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11a578a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the ChatGPT API\n",
    "def hey_chatGPT(question_text, api_key):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question_text}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers, timeout=5)\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json['choices'][0]['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e386a658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_likes_count</th>\n",
       "      <th>comment_message</th>\n",
       "      <th>attacks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953</td>\n",
       "      <td>10154314327932068_10154317256602068</td>\n",
       "      <td>0</td>\n",
       "      <td>my thats a lot of black folks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2894</td>\n",
       "      <td>435099756687754_435248720006191</td>\n",
       "      <td>4</td>\n",
       "      <td>But he did give us a better understanding of s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2104</td>\n",
       "      <td>885263181519105_886390928072997</td>\n",
       "      <td>1</td>\n",
       "      <td>VETO IT!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>917</td>\n",
       "      <td>1254553344571289_1257252654301358</td>\n",
       "      <td>0</td>\n",
       "      <td>Correction * million, not millions Time for a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1570</td>\n",
       "      <td>904974722925935_905135986243142</td>\n",
       "      <td>0</td>\n",
       "      <td>Enough liberal catholics running the house. We...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           comment_id  comment_likes_count  \\\n",
       "0    953  10154314327932068_10154317256602068                    0   \n",
       "1   2894      435099756687754_435248720006191                    4   \n",
       "2   2104      885263181519105_886390928072997                    1   \n",
       "3    917    1254553344571289_1257252654301358                    0   \n",
       "4   1570      904974722925935_905135986243142                    0   \n",
       "\n",
       "                                     comment_message  attacks  \n",
       "0                      my thats a lot of black folks        1  \n",
       "1  But he did give us a better understanding of s...        0  \n",
       "2                                         VETO IT!!!        0  \n",
       "3  Correction * million, not millions Time for a ...        1  \n",
       "4  Enough liberal catholics running the house. We...        1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# let's open some twitter data\n",
    "pd_test = pd.read_csv(\"../data/incivility.csv\")\n",
    "\n",
    "# sample\n",
    "pd_test = pd_test.sample(n=10).reset_index()\n",
    "\n",
    "# see\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b2eae6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "output = []\n",
    "# Run a loop over your dataset of reviews and prompt ChatGPT\n",
    "for i in range(len(pd_test)):\n",
    "    try: \n",
    "        print(i)\n",
    "        question = \"Is the sentiment of this text positive, neutral, or negative? \\\n",
    "        Answer only with a number: 1 if positive, 0 if neutral and -1 if negative. \\\n",
    "        Here is the text: \"\n",
    "        text = pd_test.loc[i, \"comment_message\"]\n",
    "        full_question = question + str(text)\n",
    "        output.append(hey_chatGPT(full_question, gpt_key))\n",
    "    except:\n",
    "        output.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49fa7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output\n",
    "pd_test[\"sentiment\"]= output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db281386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     comment_message sentiment\n",
      "0                      my thats a lot of black folks        -1\n",
      "1  But he did give us a better understanding of s...         0\n",
      "2                                         VETO IT!!!        -1\n",
      "3  Correction * million, not millions Time for a ...        -1\n",
      "4  Enough liberal catholics running the house. We...        -1\n",
      "5  My mother sang old shep to make me cry!!  What...        -1\n",
      "6  why are you allowing toxic Chemtrial spaying i...        -1\n",
      "7  While we were all looking the other way, sacre...        -1\n",
      "8                                      Shame on you.        -1\n",
      "9  Chris 100% of the guns used in those crimes ar...        -1\n"
     ]
    }
   ],
   "source": [
    "# see\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(pd_test[[\"comment_message\", \"sentiment\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6d8d88c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:my thats a lot of black folks \n",
      "Sentiment: -1\n",
      "Text:But he did give us a better understanding of such legal terms as \"applesauce,\" and \"jiggerly-piggerly,\" as well as the unique concept of executing innocent people simply because none of the Founding Fathers thought it necessary to spell it out in the Constitution. \n",
      "Sentiment: 0\n",
      "Text:VETO IT!!! \n",
      "Sentiment: -1\n",
      "Text:Correction * million, not millions Time for a real tax and stopping the ripoff of Ohio's resources. \n",
      "Sentiment: -1\n",
      "Text:Enough liberal catholics running the house. We want a principled conservative who is not cowered down by the liberal bullies and Obama. \n",
      "Sentiment: -1\n",
      "Text:My mother sang old shep to make me cry!!  What mean people!!  LOL \n",
      "Sentiment: -1\n",
      "Text:why are you allowing toxic Chemtrial spaying in California? \n",
      "Sentiment: -1\n",
      "Text:While we were all looking the other way, sacred Apache land (that was also property of the American people as a whole) was sold to an Australian-British mining company that will soon have the rights to leave a 2-mile crater in the area. How did this happen? Senators John McCain and Jeff Flake slipped the deal in at the last minute at the bottom of a much-needed military defense spending bill. Apache have been camped out on the sacred site of Oak Flat ever since, and this young warrior, along with a handful of others, traveled to NYC all the way from Arizona to try to bring attention to her people's plight.   Let's help this story spread and let this real life rebel know that she is not alone, and that the American people won't stand for this betrayal to us all.  Like · Reply · July 23 at 10:18am · Edited \n",
      "Sentiment: -1\n",
      "Text:Shame on you. \n",
      "Sentiment: -1\n",
      "Text:Chris 100% of the guns used in those crimes are ILLEGAL guns: stolen, straw purchase, swapped among thugs...    **************** Provide me ONE crime where the gun used was legally, purchased and registered to the thug using it. ************  It's NOT a simple step to keep them out of criminal hands.  How do you prevent thugs from stealing a gun?  How do you prevent thugs from convincing/Duping a girlfriend, relative, \"buddy\" from making a straw purchase for them?  These things are ALREADY illegal yet criminals do them everyday.  Maryland's - almost 2 year old Hand Gun Qualification licensing scheme has NOT prevented one single crime using a gun.  Maryland's feckless AK47 ban has not stopped one gun crime either.  I can go down the list of every Maryland gun law and prove NONE has ever accomplished its stated goal.  Please Chris tell me what your new scheme is?  You ARE pandering...  JL, PhD - Firearms Safety Expert, NRA Cert. Insrt.  Ballistic Forensic Scientist \n",
      "Sentiment: -1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(pd_test)):\n",
    "    print(\"Text:\" + pd_test[\"comment_message\"][i] + \" \\nSentiment: \" + pd_test[\"sentiment\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9379acb8",
   "metadata": {},
   "source": [
    "## Scaling via pair-wise comparison\n",
    "\n",
    "Now let's see how we can use GPT to do pairwise comparison. Notice, we saw in the paper that pairwise comparisons can be used as input for scaling models of ideology. But, this type of labeled data can be used for many different tasks, for example, readability and sophistication scores, as we saw earlier in the semester. \n",
    "\n",
    "Together with Lisa Signh and Leticia Bode, we are actually using a similar approach, but we human labelling, to understand levels of hummaness of social media content in the AI-Era. Next year, you can email me and I can show you some results!\n",
    "\n",
    "The code below was actually provided by Patrick Wu. So thanks to him!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e3a3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring soma\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from itertools import combinations\n",
    "from random import sample, choices\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "03577359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a client to interact with the API\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=gpt_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b703c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd499e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "p: the prompt\n",
    "system_prompt: the system prompt. The default is what is used on the ChatGPT's web interface.\n",
    "temp: temperature parameter. 1.0 is the default (for GPT-3.5, temperature ranges from 0 to 2.0)\n",
    "request_timeout: the amount of time, in seconds, to timeout the function.\n",
    "'''\n",
    "def prompting_openai_comparison(p,\n",
    "                                system_prompt='You are ChatGPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-10-28',\n",
    "                                temp=1.0):\n",
    "  # times used to sleep; these values approximate exponential backoff\n",
    "    sleepy_times = [1, 2]\n",
    "\n",
    "    for i in range(len(sleepy_times)):\n",
    "        try:\n",
    "            response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                              messages=[{\"role\": \"system\", \n",
    "                                                         \"content\": system_prompt},\n",
    "                                                        {\"role\": \"user\", \n",
    "                                                         \"content\": p}],\n",
    "                                              temperature=0)\n",
    "            break\n",
    "        except:\n",
    "          # if OpenAI's API returns an error, this lets you know and backs off for the set time, determined using the sleepy_times list\n",
    "          print('uh oh, ' + str(sleepy_times[i]))\n",
    "          time.sleep(sleepy_times[i])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd4c97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of S116 members\n",
    "#!wget https://voteview.com/static/data/out/members/S116_members.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "916a1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('S116_members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e75d9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get an ordinary version of some members of the congress\n",
    "# Add \"ordinary\" versions of senators' names\n",
    "df['bioname_ordinary'] = ['Donald Trump',\n",
    "'Doug Jones',\n",
    "'Richard Shelby',\n",
    "'Lisa Murkowski',\n",
    "'Dan Sullivan',\n",
    "'Kyrsten Sinema',\n",
    "'Martha McSally',\n",
    "'Mark Kelly',\n",
    "'John Boozman',\n",
    "'Tom Cotton',\n",
    "'Kamala Harris',\n",
    "'Dianne Feinstein',\n",
    "'Cory Gardner',\n",
    "'Michael Bennet',\n",
    "'Chris Murphy',\n",
    "'Richard Blumenthal',\n",
    "'Tom Carper',\n",
    "'Chris Coons',\n",
    "'Marco Rubio',\n",
    "'Rick Scott',\n",
    "'Johnny Isakson',\n",
    "'David Perdue',\n",
    "'Kelly Loeffler',\n",
    "'Mazie Hirono',\n",
    "'Brian Schatz',\n",
    "'Mike Crapo',\n",
    "'James Risch',\n",
    "'Dick Durbin',\n",
    "'Tammy Duckworth',\n",
    "'Todd Young',\n",
    "'Mike Braun',\n",
    "'Chuck Grassley',\n",
    "'Joni Ernst',\n",
    "'Pat Roberts',\n",
    "'Jerry Moran',\n",
    "'Mitch McConnell',\n",
    "'Rand Paul',\n",
    "'Bill Cassidy',\n",
    "'John Kennedy',\n",
    "'Angus King',\n",
    "'Susan Collins',\n",
    "'Ben Cardin',\n",
    "'Chris Van Hollen',\n",
    "'Ed Markey',\n",
    "'Elizabeth Warren',\n",
    "'Gary Peters',\n",
    "'Debbie Stabenow',\n",
    "'Amy Klobuchar',\n",
    "'Tina Smith',\n",
    "'Roger Wicker',\n",
    "'Cindy Hyde-Smith',\n",
    "'Roy Blunt',\n",
    "'Josh Hawley',\n",
    "'Steve Daines',\n",
    "'Jon Tester',\n",
    "'Deb Fischer',\n",
    "'Ben Sasse',\n",
    "'Jacky Rosen',\n",
    "'Catherine Cortez Masto',\n",
    "'Jeanne Shaheen',\n",
    "'Maggie Hassan',\n",
    "'Bob Menendez',\n",
    "'Cory Booker',\n",
    "'Martin Heinrich',\n",
    "'Tom Udall',\n",
    "'Chuck Schumer',\n",
    "'Kirsten Gillibrand',\n",
    "'Richard Burr',\n",
    "'Thom Tillis',\n",
    "'Kevin Cramer',\n",
    "'John Hoeven',\n",
    "'Rob Portman',\n",
    "'Sherrod Brown',\n",
    "'Jim Inhofe',\n",
    "'James Lankford',\n",
    "'Ron Wyden',\n",
    "'Jeff Merkley',\n",
    "'Pat Toomey',\n",
    "'Bob Casey',\n",
    "'Jack Reed',\n",
    "'Sheldon Whitehouse',\n",
    "'Tim Scott',\n",
    "'Lindsey Graham',\n",
    "'John Thune',\n",
    "'Mike Rounds',\n",
    "'Marsha Blackburn',\n",
    "'Lamar Alexander',\n",
    "'John Cornyn',\n",
    "'Ted Cruz',\n",
    "'Mike Lee',\n",
    "'Mitt Romney',\n",
    "'Patrick Leahy',\n",
    "'Bernie Sanders',\n",
    "'Mark Warner',\n",
    "'Tim Kaine',\n",
    "'Maria Cantwell',\n",
    "'Patty Murray',\n",
    "'Shelley Moore Capito',\n",
    "'Joe Manchin',\n",
    "'Tammy Baldwin',\n",
    "'Ron Johnson',\n",
    "'John Barrasso',\n",
    "'Mike Enzi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96ff8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Donald Trump\n",
    "df = df.iloc[1:,]\n",
    "\n",
    "# sample just a few\n",
    "df = df.sample(n=10).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "974dddf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>congress</th>\n",
       "      <th>chamber</th>\n",
       "      <th>icpsr</th>\n",
       "      <th>state_icpsr</th>\n",
       "      <th>district_code</th>\n",
       "      <th>state_abbrev</th>\n",
       "      <th>party_code</th>\n",
       "      <th>occupancy</th>\n",
       "      <th>last_means</th>\n",
       "      <th>...</th>\n",
       "      <th>nominate_dim1</th>\n",
       "      <th>nominate_dim2</th>\n",
       "      <th>nominate_log_likelihood</th>\n",
       "      <th>nominate_geo_mean_probability</th>\n",
       "      <th>nominate_number_of_votes</th>\n",
       "      <th>nominate_number_of_errors</th>\n",
       "      <th>conditional</th>\n",
       "      <th>nokken_poole_dim1</th>\n",
       "      <th>nokken_poole_dim2</th>\n",
       "      <th>bioname_ordinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>41111</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WI</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-45.55103</td>\n",
       "      <td>0.93161</td>\n",
       "      <td>643.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.017</td>\n",
       "      <td>Ron Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>20146</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WV</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-24.25495</td>\n",
       "      <td>0.96229</td>\n",
       "      <td>631.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.177</td>\n",
       "      <td>Shelley Moore Capito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>41900</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-61.55663</td>\n",
       "      <td>0.91133</td>\n",
       "      <td>663.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.335</td>\n",
       "      <td>Mike Braun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>40300</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AK</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-47.85393</td>\n",
       "      <td>0.92606</td>\n",
       "      <td>623.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>20330</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MD</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-104.86962</td>\n",
       "      <td>0.85451</td>\n",
       "      <td>667.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.380</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>Chris Van Hollen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>49706</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WY</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-42.60100</td>\n",
       "      <td>0.93551</td>\n",
       "      <td>639.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.414</td>\n",
       "      <td>Mike Enzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>41503</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-41.30191</td>\n",
       "      <td>0.93788</td>\n",
       "      <td>644.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>Ben Sasse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>40908</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OR</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445</td>\n",
       "      <td>-0.734</td>\n",
       "      <td>-76.21439</td>\n",
       "      <td>0.89141</td>\n",
       "      <td>663.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>-0.724</td>\n",
       "      <td>Jeff Merkley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>40703</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PA</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-100.28959</td>\n",
       "      <td>0.86059</td>\n",
       "      <td>668.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>0.197</td>\n",
       "      <td>Bob Casey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35</td>\n",
       "      <td>116</td>\n",
       "      <td>Senate</td>\n",
       "      <td>14921</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KY</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-63.71061</td>\n",
       "      <td>0.90903</td>\n",
       "      <td>668.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.201</td>\n",
       "      <td>Mitch McConnell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  congress chamber  icpsr  state_icpsr  district_code state_abbrev  \\\n",
       "0    100       116  Senate  41111           25            0.0           WI   \n",
       "1     97       116  Senate  20146           56            0.0           WV   \n",
       "2     30       116  Senate  41900           22            0.0           IN   \n",
       "3      3       116  Senate  40300           81            0.0           AK   \n",
       "4     42       116  Senate  20330           52            0.0           MD   \n",
       "5    102       116  Senate  49706           68            0.0           WY   \n",
       "6     56       116  Senate  41503           35            0.0           NE   \n",
       "7     76       116  Senate  40908           72            0.0           OR   \n",
       "8     78       116  Senate  40703           14            0.0           PA   \n",
       "9     35       116  Senate  14921           51            0.0           KY   \n",
       "\n",
       "   party_code  occupancy  last_means  ... nominate_dim1 nominate_dim2  \\\n",
       "0         200        NaN         NaN  ...         0.636        -0.140   \n",
       "1         200        NaN         NaN  ...         0.278         0.132   \n",
       "2         200        NaN         NaN  ...         0.800         0.600   \n",
       "3         200        NaN         NaN  ...         0.210        -0.316   \n",
       "4         100        NaN         NaN  ...        -0.392        -0.208   \n",
       "5         200        NaN         NaN  ...         0.545         0.199   \n",
       "6         200        NaN         NaN  ...         0.669        -0.250   \n",
       "7         100        NaN         NaN  ...        -0.445        -0.734   \n",
       "8         100        NaN         NaN  ...        -0.313         0.165   \n",
       "9         200        NaN         NaN  ...         0.404         0.020   \n",
       "\n",
       "   nominate_log_likelihood  nominate_geo_mean_probability  \\\n",
       "0                -45.55103                        0.93161   \n",
       "1                -24.25495                        0.96229   \n",
       "2                -61.55663                        0.91133   \n",
       "3                -47.85393                        0.92606   \n",
       "4               -104.86962                        0.85451   \n",
       "5                -42.60100                        0.93551   \n",
       "6                -41.30191                        0.93788   \n",
       "7                -76.21439                        0.89141   \n",
       "8               -100.28959                        0.86059   \n",
       "9                -63.71061                        0.90903   \n",
       "\n",
       "   nominate_number_of_votes  nominate_number_of_errors  conditional  \\\n",
       "0                     643.0                       25.0          NaN   \n",
       "1                     631.0                        6.0          NaN   \n",
       "2                     663.0                       29.0          NaN   \n",
       "3                     623.0                       12.0          NaN   \n",
       "4                     667.0                       39.0          NaN   \n",
       "5                     639.0                       16.0          NaN   \n",
       "6                     644.0                       15.0          NaN   \n",
       "7                     663.0                       26.0          NaN   \n",
       "8                     668.0                       50.0          NaN   \n",
       "9                     668.0                       16.0          NaN   \n",
       "\n",
       "   nokken_poole_dim1  nokken_poole_dim2      bioname_ordinary  \n",
       "0              0.610              0.017           Ron Johnson  \n",
       "1              0.326              0.177  Shelley Moore Capito  \n",
       "2              0.837              0.335            Mike Braun  \n",
       "3              0.283             -0.424        Lisa Murkowski  \n",
       "4             -0.380             -0.333      Chris Van Hollen  \n",
       "5              0.587              0.414             Mike Enzi  \n",
       "6              0.717             -0.012             Ben Sasse  \n",
       "7             -0.409             -0.724          Jeff Merkley  \n",
       "8             -0.339              0.197             Bob Casey  \n",
       "9              0.297              0.201       Mitch McConnell  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ac6b9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then get dictionaries that obtain the party and state for each senator by name\n",
    "names = list(df['bioname_ordinary'])\n",
    "state = list(df['state_abbrev'])\n",
    "party = ['R' if j==200 else 'D' if j==100 else 'I' for j in list(df['party_code'])]\n",
    "\n",
    "name_party_dict = {n: p for n,p in zip(names,party)}\n",
    "name_state_dict = {n: s for n,s in zip(names,state)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cc3fbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function samples a total number of matchups per senator. this does not mean that each senator is limited to a max of sample_size matchups\n",
    "# it means each senator will appear in at least sample_size matchups\n",
    "def generate_pairwise_matchups(items, sample_size=20, seed_value=42):\n",
    "  random.seed(seed_value)\n",
    "\n",
    "  if sample_size >= len(items) or sample_size < 1:\n",
    "    raise ValueError(\"Sample size must be between 1 and one less than the total number of tweet IDs\")\n",
    "\n",
    "  all_matchups = []\n",
    "\n",
    "  # Generate all possible pairings\n",
    "  all_combinations = list(combinations(items, 2))\n",
    "\n",
    "  for i in items:\n",
    "    # Filter matchups containing the current tweet ID\n",
    "    relevant_matchups = [pair for pair in all_combinations if i in pair]\n",
    "\n",
    "    # Shuffle the matchups\n",
    "    random.shuffle(relevant_matchups)\n",
    "\n",
    "    # Sample from these matchups up to the specified sample size\n",
    "    all_matchups.extend(relevant_matchups[:sample_size])\n",
    "\n",
    "  return all_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9259709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = generate_pairwise_matchups(names, sample_size=1, seed_value=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0421939a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matchups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc94ab8",
   "metadata": {},
   "source": [
    "Here, we note the direction of comparison. We have to use liberal and conservative differently in these prompts because, when comparing two Republicans, if I prompt ChatGPT with \"who is more liberal,\" it will often fail to answer this and reply that both senators are conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "736269ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "comparison_direction = []\n",
    "\n",
    "for j in matchups:\n",
    "    # D vs. D\n",
    "    if (name_party_dict[j[0]]=='D' or name_party_dict[j[0]]=='I') and (name_party_dict[j[1]]=='D' or name_party_dict[j[1]]=='I'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # D vs. R\n",
    "    elif (name_party_dict[j[0]]=='D' or name_party_dict[j[0]]=='I') and (name_party_dict[j[1]]=='R'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # R vs. D\n",
    "    elif (name_party_dict[j[0]]=='R') and (name_party_dict[j[1]]=='D' or name_party_dict[j[1]]=='I'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more liberal: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('liberal')\n",
    "    # R vs. R\n",
    "    elif (name_party_dict[j[0]]=='R') and (name_party_dict[j[1]]=='R'):\n",
    "        sent = 'Based on past voting records and statements, which senator is more conservative: ' + j[0] + ' (' + name_party_dict[j[0]] + '-' + name_state_dict[j[0]] + ') or ' + j[1] + ' (' + name_party_dict[j[1]] + '-' + name_state_dict[j[1]] + ')?'\n",
    "        comparison_direction.append('conservative')\n",
    "    else:\n",
    "        print('OH NO!')\n",
    "        break\n",
    "    prompts.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3a4fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the system prompt for the pairwise comparison.\n",
    "system_prompt = 'You are ChatGPT, a large language model trained by OpenAI, based on the GPT-3.5 architecture.\\nKnowledge cutoff: 2021-09\\nCurrent date: 2023-09-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d8c483c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEwBOLswBwjg",
    "outputId": "59ee1cb5-9966-45ef-d475-ca6ba00a4419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Based on past voting records and statements, which senator is more liberal: Ron Johnson (R-WI) or Chris Van Hollen (D-MD)?', 'Based on past voting records and statements, which senator is more liberal: Shelley Moore Capito (R-WV) or Bob Casey (D-PA)?', 'Based on past voting records and statements, which senator is more conservative: Mike Braun (R-IN) or Lisa Murkowski (R-AK)?', 'Based on past voting records and statements, which senator is more conservative: Lisa Murkowski (R-AK) or Mitch McConnell (R-KY)?', 'Based on past voting records and statements, which senator is more liberal: Chris Van Hollen (D-MD) or Mike Enzi (R-WY)?', 'Based on past voting records and statements, which senator is more conservative: Mike Braun (R-IN) or Mike Enzi (R-WY)?', 'Based on past voting records and statements, which senator is more conservative: Shelley Moore Capito (R-WV) or Ben Sasse (R-NE)?', 'Based on past voting records and statements, which senator is more liberal: Ben Sasse (R-NE) or Jeff Merkley (D-OR)?', 'Based on past voting records and statements, which senator is more liberal: Ron Johnson (R-WI) or Bob Casey (D-PA)?', 'Based on past voting records and statements, which senator is more liberal: Bob Casey (D-PA) or Mitch McConnell (R-KY)?']\n"
     ]
    }
   ],
   "source": [
    "print(prompts[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ced31",
   "metadata": {
    "id": "jtheSOQ6-yck"
   },
   "source": [
    "Now we're finally ready to run the pairwise comparisons. We run it in parallel because it takes a very long time to run if you iterate one prompt at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a16e4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a container\n",
    "comparison_results = []\n",
    "\n",
    "# iterate\n",
    "for p in prompts:\n",
    "    results = prompting_openai_comparison(p, system_prompt, 1.0)\n",
    "    comparison_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "74de65f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9F70pvXb7yJnFJfzKilUYkNbi7PNE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As of my last knowledge update in September 2021, Chris Van Hollen, a Democrat from Maryland, is generally considered to be more liberal than Ron Johnson, a Republican from Wisconsin. \\n\\nChris Van Hollen has a voting record and policy positions that align more closely with liberal or progressive ideals, as he is a member of the Democratic Party, which is typically associated with more liberal stances on various issues.\\n\\nRon Johnson, on the other hand, is a Republican senator from Wisconsin and is generally associated with conservative positions and policies. \\n\\nPlease note that political positions and affiliations can evolve over time, so it's advisable to check more recent sources for the most up-to-date information on the political leanings of these senators.\", role='assistant', function_call=None, tool_calls=None))], created=1713388903, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_d9767fc5b9', usage=CompletionUsage(completion_tokens=146, prompt_tokens=87, total_tokens=233))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at it \n",
    "comparison_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "677c00e7",
   "metadata": {
    "id": "If7vQcBIEKb6"
   },
   "outputs": [],
   "source": [
    "# Extract the text answer from ChatGPT responses\n",
    "def get_text_from_chatgpt(responses):\n",
    "  return [responses[i].choices[0].message.content for i in range(len(responses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c444d3a",
   "metadata": {
    "id": "4BqEETdHEUhI"
   },
   "outputs": [],
   "source": [
    "comparisons_text = get_text_from_chatgpt(comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3db795e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb6h_yBnEZHC",
    "outputId": "3bab01e4-e01e-46f5-8137-c657d1e2d864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last knowledge update in September 2021, Chris Van Hollen, a Democrat from Maryland, is generally considered to be more liberal than Ron Johnson, a Republican from Wisconsin. \n",
      "\n",
      "Chris Van Hollen has a voting record and policy positions that align more closely with liberal or progressive ideals, as he is a member of the Democratic Party, which is typically associated with more liberal stances on various issues.\n",
      "\n",
      "Ron Johnson, on the other hand, is a Republican senator from Wisconsin and is generally associated with conservative positions and policies. \n",
      "\n",
      "Please note that political positions and affiliations can evolve over time, so it's advisable to check more recent sources for the most up-to-date information on the political leanings of these senators.\n"
     ]
    }
   ],
   "source": [
    "# This is what a pairwise comparison looks like.\n",
    "print(comparisons_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c328a",
   "metadata": {
    "id": "VCvcOOqsDq_j"
   },
   "source": [
    "Now we need to extract the answers from our comparisons. We'll append our answers from before and ask ChatGPT to extract the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1863fe63",
   "metadata": {
    "id": "8BFHJoMxDnCp"
   },
   "outputs": [],
   "source": [
    "extracting_answer_prompt = []\n",
    "\n",
    "for i in range(len(comparisons_text)):\n",
    "    if comparison_direction[i]=='liberal':\n",
    "        sent = 'Text: \"' + comparisons_text[i] + '\"\\n\\nIn the above Text, who is described to be the more liberal, more progressive, or less conservative senator: ' + matchups[i][0] + ' or ' + matchups[i][1] + '? Return only the full name without party affiliation or state information. If one senator is described as more conservative, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more liberal, more progressive, less conservative, more conservative, or more moderate, reply with \"Tie.\"'\n",
    "    elif comparison_direction[i]=='conservative':\n",
    "        sent = 'Text: \"' + comparisons_text[i] + '\"\\n\\nIn the above Text, who is described to be the more conservative or less liberal senator: ' + matchups[i][0] + ' or ' + matchups[i][1] + '? Return only the full name without party affiliation or state information. If one senator is described as more liberal, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more conservative, less liberal, more liberal, or more moderate, reply with \"Tie.\"'\n",
    "    extracting_answer_prompt.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a3a8668",
   "metadata": {
    "id": "Ip_xDa7bDya1"
   },
   "outputs": [],
   "source": [
    "system_prompt_extraction = 'You are reading a Text and extracting information from it according to the prompt. Follow the directions exactly.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bedb7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text: \"As of my last knowledge update in September 2021, Chris Van Hollen, a Democrat from Maryland, is generally considered to be more liberal than Ron Johnson, a Republican from Wisconsin. \\n\\nChris Van Hollen has a voting record and policy positions that align more closely with liberal or progressive ideals, as he is a member of the Democratic Party, which is typically associated with more liberal stances on various issues.\\n\\nRon Johnson, on the other hand, is a Republican senator from Wisconsin and is generally associated with conservative positions and policies. \\n\\nPlease note that political positions and affiliations can evolve over time, so it\\'s advisable to check more recent sources for the most up-to-date information on the political leanings of these senators.\"\\n\\nIn the above Text, who is described to be the more liberal, more progressive, or less conservative senator: Ron Johnson or Chris Van Hollen? Return only the full name without party affiliation or state information. If one senator is described as more conservative, return the other senator\\'s name. If one senator is described as more moderate, return the other senator\\'s name. If neither senators are described to be more liberal, more progressive, less conservative, more conservative, or more moderate, reply with \"Tie.\"'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see this!\n",
    "extracting_answer_prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bad6fdef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7rxmUVQEolE",
    "outputId": "dd5d69cb-701a-435c-ec5c-081af4d22d54"
   },
   "outputs": [],
   "source": [
    "# create a container\n",
    "extraction = []\n",
    "\n",
    "# iterate\n",
    "for p in extracting_answer_prompt:\n",
    "    results = prompting_openai_comparison(p, system_prompt, 1.0)\n",
    "    extraction.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5686f8c4",
   "metadata": {
    "id": "jFqjJJ_8Eybm"
   },
   "outputs": [],
   "source": [
    "extraction_text = get_text_from_chatgpt(extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "061e55a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris Van Hollen',\n",
       " 'Bob Casey',\n",
       " 'Mike Braun',\n",
       " 'Mitch McConnell',\n",
       " 'Chris Van Hollen',\n",
       " 'Tie.',\n",
       " 'Ben Sasse',\n",
       " 'Jeff Merkley',\n",
       " 'Bob Casey',\n",
       " 'Bob Casey']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8c8cb2a4",
   "metadata": {
    "id": "2ZBuHNk5E9jp"
   },
   "outputs": [],
   "source": [
    "# this function simply removes the period at the sentences\n",
    "def remove_period(sentence):\n",
    "    if sentence.endswith('.'):\n",
    "        sentence = sentence[:-1]\n",
    "    return sentence\n",
    "\n",
    "# this function simply removes the 'Senator ' prefix. For example, it returns \"Dianne Feinstein\" if the input text is \"Senator Dianne Feinstein\"\n",
    "def remove_senator_prefix(input_string):\n",
    "    if input_string.startswith(\"Senator \"):\n",
    "        return input_string[8:]\n",
    "    else:\n",
    "        return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2c39f3b1",
   "metadata": {
    "id": "VQB2YpreE8A5"
   },
   "outputs": [],
   "source": [
    "extraction_text = [remove_period(t) for t in extraction_text]\n",
    "extraction_text = [remove_senator_prefix(t) for t in extraction_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "616223ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zF94uPOFGQK",
    "outputId": "0087d2b5-50d2-44f3-9c62-9e35cb2bfac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chris Van Hollen\n"
     ]
    }
   ],
   "source": [
    "print(extraction_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6311aa",
   "metadata": {
    "id": "gq4wIEduFPsq"
   },
   "source": [
    "We then use a function to check that every extraction was correct. Sometimes it will still not correctly extract the answer, which means we have to step in and manually fix it. If the function prints nothing, great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6500be5",
   "metadata": {
    "id": "0KLnXKWUFgQR"
   },
   "source": [
    "This step will make the final dataframe with the resultant matchups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "22478c46",
   "metadata": {
    "id": "pZ7bARJeFX2a"
   },
   "outputs": [],
   "source": [
    "def make_final_df(matchups, chatgpt_answers, final_answers, comparison_direction):\n",
    "    sen1 = [j[0] for j in matchups]\n",
    "    sen2 = [j[1] for j in matchups]\n",
    "\n",
    "    matchup_results = pd.DataFrame({'matchup': matchups,\n",
    "                                    'senator1': sen1,\n",
    "                                    'senator2': sen2,\n",
    "                                    'chatgpt_response': chatgpt_answers,\n",
    "                                    'final_answers': final_answers,\n",
    "                                    'comparison_direction': comparison_direction})\n",
    "\n",
    "    opposite = []\n",
    "    sen1_win = []\n",
    "    sen2_win = []\n",
    "\n",
    "    for i in range(len(matchup_results['matchup'])):\n",
    "        if matchup_results['comparison_direction'][i]=='liberal':\n",
    "            if matchup_results['final_answers'][i]==matchup_results['senator1'][i]:\n",
    "                sen1_win.append(0.0)\n",
    "                sen2_win.append(1.0)\n",
    "            elif matchup_results['final_answers'][i]==matchup_results['senator2'][i]:\n",
    "                sen1_win.append(1.0)\n",
    "                sen2_win.append(0.0)\n",
    "            elif matchup_results['final_answers'][i]=='Tie':\n",
    "                sen1_win.append(0.5)\n",
    "                sen2_win.append(0.5)\n",
    "        elif matchup_results['comparison_direction'][i]=='conservative':\n",
    "            if matchup_results['final_answers'][i]==matchup_results['senator1'][i]:\n",
    "                sen1_win.append(1.0)\n",
    "                sen2_win.append(0.0)\n",
    "            elif matchup_results['final_answers'][i]==matchup_results['senator2'][i]:\n",
    "                sen1_win.append(0.0)\n",
    "                sen2_win.append(1.0)\n",
    "            elif matchup_results['final_answers'][i]=='Tie':\n",
    "                sen1_win.append(0.5)\n",
    "                sen2_win.append(0.5)\n",
    "        else:\n",
    "            print(str(i) + ' is a defective outcome')\n",
    "\n",
    "    matchup_results['win1'] = sen1_win\n",
    "    matchup_results['win2'] = sen2_win\n",
    "\n",
    "    return matchup_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "565ebe1a",
   "metadata": {
    "id": "Au6wNzobFks2"
   },
   "outputs": [],
   "source": [
    "final_df = make_final_df(matchups=matchups,\n",
    "                         chatgpt_answers=comparisons_text,\n",
    "                         final_answers=extraction_text,\n",
    "                         comparison_direction=comparison_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f046048e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "mWP71OiXFnRZ",
    "outputId": "2fb2b438-12fc-4e6b-b4bb-35a86713d80a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchup</th>\n",
       "      <th>senator1</th>\n",
       "      <th>senator2</th>\n",
       "      <th>chatgpt_response</th>\n",
       "      <th>final_answers</th>\n",
       "      <th>comparison_direction</th>\n",
       "      <th>win1</th>\n",
       "      <th>win2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Ron Johnson, Chris Van Hollen)</td>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>Chris Van Hollen</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Chris Van Hollen</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Shelley Moore Capito, Bob Casey)</td>\n",
       "      <td>Shelley Moore Capito</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mike Braun, Lisa Murkowski)</td>\n",
       "      <td>Mike Braun</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Mike Braun</td>\n",
       "      <td>conservative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Lisa Murkowski, Mitch McConnell)</td>\n",
       "      <td>Lisa Murkowski</td>\n",
       "      <td>Mitch McConnell</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Mitch McConnell</td>\n",
       "      <td>conservative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Chris Van Hollen, Mike Enzi)</td>\n",
       "      <td>Chris Van Hollen</td>\n",
       "      <td>Mike Enzi</td>\n",
       "      <td>Chris Van Hollen, a Democrat from Maryland, is...</td>\n",
       "      <td>Chris Van Hollen</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Mike Braun, Mike Enzi)</td>\n",
       "      <td>Mike Braun</td>\n",
       "      <td>Mike Enzi</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Tie</td>\n",
       "      <td>conservative</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Shelley Moore Capito, Ben Sasse)</td>\n",
       "      <td>Shelley Moore Capito</td>\n",
       "      <td>Ben Sasse</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Ben Sasse</td>\n",
       "      <td>conservative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Ben Sasse, Jeff Merkley)</td>\n",
       "      <td>Ben Sasse</td>\n",
       "      <td>Jeff Merkley</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Jeff Merkley</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Ron Johnson, Bob Casey)</td>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>As of my last knowledge update in September 20...</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Bob Casey, Mitch McConnell)</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>Mitch McConnell</td>\n",
       "      <td>Bob Casey, a Democrat from Pennsylvania, is ge...</td>\n",
       "      <td>Bob Casey</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             matchup              senator1          senator2  \\\n",
       "0    (Ron Johnson, Chris Van Hollen)           Ron Johnson  Chris Van Hollen   \n",
       "1  (Shelley Moore Capito, Bob Casey)  Shelley Moore Capito         Bob Casey   \n",
       "2       (Mike Braun, Lisa Murkowski)            Mike Braun    Lisa Murkowski   \n",
       "3  (Lisa Murkowski, Mitch McConnell)        Lisa Murkowski   Mitch McConnell   \n",
       "4      (Chris Van Hollen, Mike Enzi)      Chris Van Hollen         Mike Enzi   \n",
       "5            (Mike Braun, Mike Enzi)            Mike Braun         Mike Enzi   \n",
       "6  (Shelley Moore Capito, Ben Sasse)  Shelley Moore Capito         Ben Sasse   \n",
       "7          (Ben Sasse, Jeff Merkley)             Ben Sasse      Jeff Merkley   \n",
       "8           (Ron Johnson, Bob Casey)           Ron Johnson         Bob Casey   \n",
       "9       (Bob Casey, Mitch McConnell)             Bob Casey   Mitch McConnell   \n",
       "\n",
       "                                    chatgpt_response     final_answers  \\\n",
       "0  As of my last knowledge update in September 20...  Chris Van Hollen   \n",
       "1  As of my last knowledge update in September 20...         Bob Casey   \n",
       "2  As of my last knowledge update in September 20...        Mike Braun   \n",
       "3  As of my last knowledge update in September 20...   Mitch McConnell   \n",
       "4  Chris Van Hollen, a Democrat from Maryland, is...  Chris Van Hollen   \n",
       "5  As of my last knowledge update in September 20...               Tie   \n",
       "6  As of my last knowledge update in September 20...         Ben Sasse   \n",
       "7  As of my last knowledge update in September 20...      Jeff Merkley   \n",
       "8  As of my last knowledge update in September 20...         Bob Casey   \n",
       "9  Bob Casey, a Democrat from Pennsylvania, is ge...         Bob Casey   \n",
       "\n",
       "  comparison_direction  win1  win2  \n",
       "0              liberal   1.0   0.0  \n",
       "1              liberal   1.0   0.0  \n",
       "2         conservative   1.0   0.0  \n",
       "3         conservative   0.0   1.0  \n",
       "4              liberal   0.0   1.0  \n",
       "5         conservative   0.5   0.5  \n",
       "6         conservative   0.0   1.0  \n",
       "7              liberal   1.0   0.0  \n",
       "8              liberal   1.0   0.0  \n",
       "9              liberal   0.0   1.0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b770ad4",
   "metadata": {},
   "source": [
    "From here would just need to go the R to do the Bradley Terry model. Happy to share code about this as well, but that would be too much for today!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4fca67",
   "metadata": {},
   "source": [
    "## Generating survey responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b489f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the ChatGPT API\n",
    "def survey_chatGPT(profile, prompt, api_key):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo-0301\",\n",
    "        \"temperature\": 0.2,\n",
    "        \"messages\": [{\"role\": \"system\", \n",
    "                      \"content\": profile}, \n",
    "                    {\"role\":\"user\", \n",
    "                    \"content\":prompt}]\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", \n",
    "                             json=data, \n",
    "                             headers=headers, timeout=5)\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "99fce30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_profile(age, race, gender, educ, inc, pid):\n",
    "    profile = \"You are a \" + str(age) + \" year old \" + race + \" \"+ gender + \" with a \" + educ + \", earning $\" + inc + \" per year . \" + \"You are a registered \" + pid + \" living in the USA in 2019. \"\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "af7dd62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a 18 year old latino female with a post-graduate, earning $100,000 per year . You are a registered Democrat living in the USA in 2019. '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test one profile\n",
    "profile = gen_profile(18, \"latino\", \"female\", \"post-graduate\", \"100,000\", \"Democrat\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ddfbe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Provide responses from this person's perspective.\\n\"\\\n",
    "         \"Use only knowledge about politics that they would have.\\n\"\\\n",
    "         \"Format the output as a csv table with the following format:\\n\"\\\n",
    "         \"group, thermometer\\n\"\\\n",
    "         \"The following questions ask about individuals' feelings \"\\\n",
    "         \"toward different groups.\\n\"\\\n",
    "         \"Responses should be given on a scale from 0 (meaning cold \"\\\n",
    "         \"feelings) to 100 (meaning warm feelings).\\n\"\\\n",
    "         \"Ratings between 50 degrees and 100 degrees mean that\\n\"\\\n",
    "         \"you feel favorable and warm toward the group. Ratings \"\\\n",
    "         \"between 0\\n\"\\\n",
    "         \"degrees and 50 degrees mean that you don't feel \"\\\n",
    "         \"favorable toward\\n\"\\\n",
    "         \"the group and that you don't care too much for that \"\\\n",
    "         \"group. You\\n\"\\\n",
    "         \"would rate the group at the 50 degree mark if you don't feel\\n\"\\\n",
    "         \"particularly warm or cold toward the group.\\n\"\\\n",
    "         \"How do you feel toward the following groups?\\n\"\\\n",
    "         \"The Democratic Party?\\n\"\\\n",
    "         \"The Republican Party?\\n\"\\\n",
    "         \"Democrats?\\n\"\\\n",
    "         \"Republicans?\\n\"\\\n",
    "         \"Black Americans?\\n\"\\\n",
    "         \"White Americans?\\n\"\\\n",
    "         \"Hispanic Americans?\\n\"\\\n",
    "         \"Asian Americans?\\n\"\\\n",
    "         \"Muslims?\\n\"\\\n",
    "         \"Christians?\\n\"\\\n",
    "         \"Immigrants?\\n\"\\\n",
    "         \"Gays and Lesbians?\\n\"\\\n",
    "         \"Jews?\\n\"\\\n",
    "         \"Liberals?\\n\"\\\n",
    "         \"Conservatives?\\n\"\\\n",
    "         \"Women?\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9b7c20df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9F76v1GZFz2rp6CIzbPAuaRmgddWp', 'object': 'chat.completion', 'created': 1713389281, 'model': 'gpt-3.5-turbo-0301', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'group,thermometer\\nThe Democratic Party,90\\nThe Republican Party,20\\nDemocrats,85\\nRepublicans,25\\nBlack Americans,90\\nWhite Americans,70\\nHispanic Americans,85\\nAsian Americans,80\\nMuslims,70\\nChristians,60\\nImmigrants,90\\nGays and Lesbians,90\\nJews,80\\nLiberals,90\\nConservatives,30\\nWomen,95'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 262, 'completion_tokens': 89, 'total_tokens': 351}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "# get an output\n",
    "output = survey_chatGPT(profile, prompt, gpt_key)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d4c8b9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9F76v1GZFz2rp6CIzbPAuaRmgddWp',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1713389281,\n",
       " 'model': 'gpt-3.5-turbo-0301',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'group,thermometer\\nThe Democratic Party,90\\nThe Republican Party,20\\nDemocrats,85\\nRepublicans,25\\nBlack Americans,90\\nWhite Americans,70\\nHispanic Americans,85\\nAsian Americans,80\\nMuslims,70\\nChristians,60\\nImmigrants,90\\nGays and Lesbians,90\\nJews,80\\nLiberals,90\\nConservatives,30\\nWomen,95'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 262, 'completion_tokens': 89, 'total_tokens': 351},\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "db7efafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = output[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3115d4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>thermometer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Democratic Party</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Republican Party</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrats</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Republicans</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Americans</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>White Americans</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hispanic Americans</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asian Americans</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Muslims</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Christians</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Immigrants</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gays and Lesbians</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jews</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Liberals</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Conservatives</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Women</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   group thermometer\n",
       "0   The Democratic Party          90\n",
       "1   The Republican Party          20\n",
       "2              Democrats          85\n",
       "3            Republicans          25\n",
       "4        Black Americans          90\n",
       "5        White Americans          70\n",
       "6     Hispanic Americans          85\n",
       "7        Asian Americans          80\n",
       "8                Muslims          70\n",
       "9             Christians          60\n",
       "10            Immigrants          90\n",
       "11     Gays and Lesbians          90\n",
       "12                  Jews          80\n",
       "13              Liberals          90\n",
       "14         Conservatives          30\n",
       "15                 Women          95"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get response\n",
    "response = output[\"choices\"][0][\"message\"]['content']\n",
    "\n",
    "# clean\n",
    "lines = response.split('\\n')\n",
    "data = [line.split(',') for line in lines]\n",
    "\n",
    "# build data frame \n",
    "pd.DataFrame(data[1:], columns=data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed58023",
   "metadata": {
    "id": "OJrWeMmZlV5P"
   },
   "source": [
    "# Using Meta's LLaMa2\n",
    "\n",
    "Instead of using Open AI models, we can (and I think we should) work with open source LLM models, such as LLaMa2 from Meta. You can use the model after getting access to it on Hugging face!\n",
    "\n",
    "I suggest you to run this on a Google Colab with GPU! Let's just see a simple example here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "995535da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzmcNRhnl3tt",
    "outputId": "26549a84-0939-4f4b-c6f0-8a85dba109ed"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a312fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbd4a7d2316410086001df8b912ddd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05812f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYjAkRzToC8E",
    "outputId": "4d02b0cf-0cb8-41e4-8c31-4064ad2db1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/tb186/anaconda3/lib/python3.11/site-packages (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (2.4.0.dev20240416)\n",
      "Requirement already satisfied: huggingface-hub in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/tb186/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/tb186/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/tb186/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73d1aab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609,
     "referenced_widgets": [
      "4cbcdb3cfcdf4c46b854df86247d6c6b",
      "76d618452b624b509498271ab007481c",
      "92d8673b14244778999225f887887f8d",
      "176745fc5906477ebf3e612bbdb1caa6",
      "7fd2b04cb82347ddabc2b1ff1198f1a1",
      "6b950c69314f4dde811168bca454470d",
      "3002d62fa0bc44af98a68d75e564e277",
      "63453d598ece42a0bc2a38e9408a24c6",
      "4d8424a29ecb453db35a0a50490ea679",
      "94b93a6a23674b5c9dfb7c0d0cfe4ddc",
      "d0af2661af884a56806840d9fa204efd",
      "38d79d8a668f4b17833aa89c76eb2b3c",
      "4806a79d4ab943eca27528cfcfd039a6",
      "1e413b059182429fbcef3bcd8abfeb0b",
      "8fbdee67b91f4a3bb6ccfec6b229461f",
      "9eb68e04518b4d0fb982e5ee3fd0d6e3",
      "afc1ee8496de442e94e1c00235b39df1",
      "82f61ce852074244b44ce21985703a17",
      "40ba6a38890a48a2a71f8ec63216782f",
      "949f5f479170421a9ba0de747f9c7389",
      "e5d508eeba7a478189080af01c43cf1d",
      "cbadb104f68646219b51eac0209d0c7f",
      "d779419dd3d64a47ad7568b4a7ea0314",
      "d011f9a50d91472e8da4f2a05097eccf",
      "d8ab95b01cc8401f9980514167846b16",
      "c1aba4fdd74542f8a90ca8e92ba101a1",
      "aa50659235cf4104b6cd9a23c77b924e",
      "203ccb14e7d948169f49e4dfcb1ba320",
      "82cf63b4a3e14ab8a05a602f04d89f7f",
      "c50751e33a4c4d038da536d706060ac3",
      "f2791d104d2f4d93a9addf6fad4626cf",
      "225e9725eddc4c449fdeb5bd322c793b",
      "af108c59ff724f17a4c00940aa56d6f0",
      "6ace03bc6a884121933ccc77056b38c2",
      "d661be16531a4f959c9eeb009d2962d6",
      "95af691a08f34e06b4ce4cd51ab7fcc2",
      "c79f132dc3644278a8f64c068f891efb",
      "18472defd8d44701a8b7bce0d227289d",
      "1c428e71554f4ad185ef8eeef4d25c80",
      "d3122caf3316416cb7cb3acc8d076e34",
      "bf076d5f6c8c44f6a5827295528d2079",
      "1b3ca02340324b80b3f9e740644d57d8",
      "bf324084742e4c8a93a44712598f6c53",
      "aff8d13b49eb47cd9923569bbbe327c1",
      "67d94c1e9cab48c2bc243d19652a0d30",
      "f3b9ac75997f47a487b210fa7e41e17e",
      "73ae036843b846e59e0cb58cacbd9188",
      "7ef0d0f462d044319ab80e40e1a741e4",
      "1907cbb018194e5599b5350ea7df3164",
      "3979977dec5f4099a661941b6f867705",
      "65a606af203245488f46c8e99103e987",
      "9618bd4489dc4f33b8257a94230c33e0",
      "cee93bc6484a4e59acfa86fe77d8ec70",
      "4b8926a9576a4725bd2ccd79fa59aba4",
      "07fb8b6af64041d9acdb4a5a17b4155d",
      "a30814c087fe4eba822b00da6d85b0d0",
      "1f261a8528e44cf3aee7f847cc32f1f8",
      "97735000fefa4c079a97f6a91b6380be",
      "54611321826b42e29b81dbfe3ce57985",
      "4d694afd5d2a45f6aa22551e8192335c",
      "55b6735e3e014c5fbf326d531ab29be8",
      "0475662c90b54b39bb932916c23bc2b6",
      "be71ca2a981340e3988538e5a6df65fb",
      "1f4b11e13470470991d7d385940bb9f4",
      "ee75f5a03ed74056a8b3a01c14498093",
      "06a08ec3cf92497e9c8fff2354f5db89",
      "40db8eb8a7f3443687a2b64a729e5db6",
      "652d6ce29d6a40e893ee0b04501b98c3",
      "432ca735926249358c252f50e6787f60",
      "15f3b5abc2cf4829bbba233dd8850694",
      "541f7e57737d40b8b6a7eb5f6a31da58",
      "ac8862a27d914b07add94e5e80ca4575",
      "c18d7aa1b6fc4a3b84a50ad2847cc642",
      "a86647978dbc41ba89d911a64dcca77a",
      "7197683b177748698e196fb8ba548a72",
      "1275f1f4eef649f98bd8350b653aac7a",
      "bbe4551e16544d9a8a264cdbee51215e",
      "90d0be5b047940b5bbf9689bd735063a",
      "1c551fb4ec8644b68019121a0cd0fa6b",
      "e94a34290c8f4789b7d34acfb8898bf9",
      "01c7642ff44f47538bf78f7f32df34cb",
      "113bac44686141558af23d789fe2946f",
      "810958f726944251ac7ef1cb1c259ea7",
      "20a4e52d59a04d4fb3468c975833bfc2",
      "da6fffc5aebf4586abd0b2e0ac460fed",
      "eab5ef56e9fe447c85085ba204ed2331",
      "d18dead40fb1479899be368e7a2cb858",
      "4393071b428e4f30bd18019db4562360",
      "7b3fcb3cb6f64eec8a86944f12ba1ce5",
      "a3fe102a563b4a4f9aa75333d9ffffe0",
      "f4f6369ff4ce404ba025fb74d885030d",
      "876534fb28fb41f2960e4ab94cb903c0",
      "5324fb96b84e4818a1548c31fdbd064c",
      "a628b5f018fc4e21b7ad7be87343637b",
      "a3e5358b036d4be9836cd22294c24e4a",
      "06884eff45194ae9aee2fe0b51ab2b19",
      "7ebcceb4723a413b9308d75c544206e7",
      "42acd6f75fe94e44a6e956e0bc488f4c",
      "7b7f018295c14dd9b052bd25d2dd589b",
      "53245232162f4e8297226e7543e56fdf",
      "2bab8c6ece2b4c0d8adde42bbd692978",
      "1007101f03cb406589c0de7e85a15b99",
      "0a3332d0dc0a40738f7d4afc7fa8ea7a",
      "1728a8dfe2d84768bc5c48801be116a5",
      "9fefa1d7328340bf84620a6f7e3fc285",
      "72cd87b71a7c4d7f954a748d904fe15b",
      "1324d9eea3f64815a4ca2fa74e6d89b5",
      "8f20e654197a4f9caeec695fa47c2897",
      "9a48df09a6b84530b4dd3d09583cc5d2",
      "ec32b8ee27024b949be79260ec4cb5c0",
      "df9b548bc30245b5b34f80650bd8737e",
      "a3e0f2e349bc471a8b583a4629206a1f",
      "2b891d82091548338bd3d8da6de09982",
      "a52392ba0c67434e8b7820557c177d13",
      "aa159a553a90490cb8a5240b4789305f",
      "3584bf0f3b944247a32c9714584ab298",
      "a4f0a87bcc044144bf643454ada1271f",
      "36c7facc7daf4bcbaac2cd227ceb199b",
      "babee5db6adc4801bd2c247df6bfe683",
      "823c7d0c08e7471c8da0197904b84c51",
      "a8fec212da8b44d1b452bf09116f423c"
     ]
    },
    "id": "2VQwzMMBmqoF",
    "outputId": "b9a83df0-a758-421d-d2a9-c69088445824"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57722f2a08e74a2b9f0c327025e0d9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\" # Calling the smallest model of 7 billion parameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "# First time, download will take a bit (depending on connection). File is around 13GB.\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"mps\") # If you are using a Mac.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13860f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIDgsE8gqX1v",
    "outputId": "d7663f5b-78d1-46eb-bc6e-dba5fae89e4a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  You are not a voice for the people of Kansas.      You are a voice for the people of Washington, D.C. and New York City.      You are not a voice for the people of Kansas.      You are a voice for the people of the United States.      You are not a voice for the people of the United States.      You are a voice for the people of the world.      You are not a voice for the people of the world.      You are a voice for the people of the universe.      You are not a voice for the people of the universe.      You are a voice for the people of the cosmos.      You are not a voice for the people of the cosmos\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    \"Is the sentiment of this text positive, neutral, or negative? \\\n",
    "    Answer only with a number: 1 if positive, 0 if neutralm and -1 if negative. \\\n",
    "    Here is the text: Oh, Pat, you know it is about President Obama naming the Supreme Court Justice.\\\n",
    "    Don't drag your feet on this, and don't be an obstacle to yet another proposal by the President.  \\\n",
    "    You are way to old and removed from Kansas to be a voice for us. \",\n",
    "    do_sample=True, # this prevents the model from just picking the most likely word at every step greedily\n",
    "    top_k=1, # limit the number of words the model considers when decoding before randomly sampling from the word probabilities.\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=250, # what is the length of sequence we want?\n",
    "    return_full_text = False,\n",
    ")\n",
    "\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
